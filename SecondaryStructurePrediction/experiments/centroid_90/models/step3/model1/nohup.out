2020-04-25 05:51:33.445770: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-25 05:51:33.538452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-25 05:51:33.539872: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x1a90b90 executing computations on platform CUDA. Devices:
2020-04-25 05:51:33.539893: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): GeForce GTX 1070, Compute Capability 6.1
2020-04-25 05:51:33.559501: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600165000 Hz
2020-04-25 05:51:33.559916: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2154fd0 executing computations on platform Host. Devices:
2020-04-25 05:51:33.559940: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2020-04-25 05:51:33.560045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.93GiB freeMemory: 7.53GiB
2020-04-25 05:51:33.560066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2020-04-25 05:51:33.560926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-25 05:51:33.560948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2020-04-25 05:51:33.560960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2020-04-25 05:51:33.561051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7327 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
Using TensorFlow backend.
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /home/polina/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/polina/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Train on 19089 samples, validate on 2120 samples
Epoch 1/500
 - 63s - loss: 0.1429 - f_mera: 0.7161 - val_loss: 0.1525 - val_f_mera: 0.6968
Epoch 2/500
 - 61s - loss: 0.1410 - f_mera: 0.7188 - val_loss: 0.1521 - val_f_mera: 0.6966
Epoch 3/500
 - 61s - loss: 0.1405 - f_mera: 0.7175 - val_loss: 0.1513 - val_f_mera: 0.6973
Epoch 4/500
 - 61s - loss: 0.1401 - f_mera: 0.7177 - val_loss: 0.1569 - val_f_mera: 0.6853
Epoch 5/500
 - 61s - loss: 0.1401 - f_mera: 0.7173 - val_loss: 0.1531 - val_f_mera: 0.6944
2020-04-25 05:58:45.743801: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-25 05:58:45.840894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-25 05:58:45.841339: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x3114930 executing computations on platform CUDA. Devices:
2020-04-25 05:58:45.841357: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): GeForce GTX 1070, Compute Capability 6.1
2020-04-25 05:58:45.859507: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600165000 Hz
2020-04-25 05:58:45.859894: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x37d90e0 executing computations on platform Host. Devices:
2020-04-25 05:58:45.859924: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2020-04-25 05:58:45.860047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.93GiB freeMemory: 7.53GiB
2020-04-25 05:58:45.860069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2020-04-25 05:58:45.860938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-25 05:58:45.860956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2020-04-25 05:58:45.860965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2020-04-25 05:58:45.861040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7328 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
Using TensorFlow backend.
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /home/polina/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/polina/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2020-04-25 06:00:04.809189: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-25 06:00:04.876420: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-25 06:00:04.876708: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x19b9930 executing computations on platform CUDA. Devices:
2020-04-25 06:00:04.876730: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): GeForce GTX 1070, Compute Capability 6.1
2020-04-25 06:00:04.899464: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600165000 Hz
2020-04-25 06:00:04.899742: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x207e0e0 executing computations on platform Host. Devices:
2020-04-25 06:00:04.899763: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2020-04-25 06:00:04.899856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.93GiB freeMemory: 86.62MiB
2020-04-25 06:00:04.899872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2020-04-25 06:00:04.900263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-25 06:00:04.900276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2020-04-25 06:00:04.900282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2020-04-25 06:00:04.900333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 86 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
Using TensorFlow backend.
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /home/polina/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2020-04-25 06:00:04.923673: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 86.62M (90832896 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-04-25 06:00:32.247302: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-25 06:00:32.341971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-25 06:00:32.342414: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2666930 executing computations on platform CUDA. Devices:
2020-04-25 06:00:32.342431: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): GeForce GTX 1070, Compute Capability 6.1
2020-04-25 06:00:32.363505: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600165000 Hz
2020-04-25 06:00:32.363908: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2d2b0e0 executing computations on platform Host. Devices:
2020-04-25 06:00:32.363940: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2020-04-25 06:00:32.364067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.93GiB freeMemory: 7.53GiB
2020-04-25 06:00:32.364088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2020-04-25 06:00:32.364939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-25 06:00:32.364957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2020-04-25 06:00:32.364965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2020-04-25 06:00:32.365032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7327 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
Using TensorFlow backend.
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /home/polina/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/polina/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Train on 19089 samples, validate on 2120 samples
Epoch 1/500
 - 63s - loss: 0.1416 - f_mera: 0.7159 - val_loss: 0.1518 - val_f_mera: 0.6964
Epoch 2/500
 - 61s - loss: 0.1408 - f_mera: 0.7163 - val_loss: 0.1514 - val_f_mera: 0.6977
Epoch 3/500
 - 61s - loss: 0.1408 - f_mera: 0.7160 - val_loss: 0.1518 - val_f_mera: 0.6969
Epoch 4/500
 - 61s - loss: 0.1403 - f_mera: 0.7168 - val_loss: 0.1527 - val_f_mera: 0.6927
Epoch 5/500
 - 61s - loss: 0.1399 - f_mera: 0.7171 - val_loss: 0.1512 - val_f_mera: 0.6973
Epoch 6/500
 - 61s - loss: 0.1399 - f_mera: 0.7171 - val_loss: 0.1504 - val_f_mera: 0.6986
Epoch 7/500
 - 61s - loss: 0.1399 - f_mera: 0.7170 - val_loss: 0.1511 - val_f_mera: 0.6969
Epoch 8/500
 - 61s - loss: 0.1393 - f_mera: 0.7172 - val_loss: 0.1516 - val_f_mera: 0.6953
Epoch 9/500
 - 61s - loss: 0.1387 - f_mera: 0.7188 - val_loss: 0.1496 - val_f_mera: 0.6978
Epoch 10/500
 - 61s - loss: 0.1386 - f_mera: 0.7191 - val_loss: 0.1535 - val_f_mera: 0.6838
Epoch 11/500
 - 61s - loss: 0.1386 - f_mera: 0.7185 - val_loss: 0.1553 - val_f_mera: 0.6602
Epoch 12/500
 - 61s - loss: 0.1388 - f_mera: 0.7183 - val_loss: 0.1487 - val_f_mera: 0.7012
Epoch 13/500
 - 61s - loss: 0.1385 - f_mera: 0.7189 - val_loss: 0.1495 - val_f_mera: 0.7004
Epoch 14/500
 - 61s - loss: 0.1383 - f_mera: 0.7192 - val_loss: 0.1487 - val_f_mera: 0.7008
Epoch 15/500
 - 61s - loss: 0.1381 - f_mera: 0.7193 - val_loss: 0.1501 - val_f_mera: 0.6983
Epoch 16/500
 - 61s - loss: 0.1380 - f_mera: 0.7197 - val_loss: 0.1487 - val_f_mera: 0.6992
Epoch 17/500
 - 61s - loss: 0.1382 - f_mera: 0.7192 - val_loss: 0.1492 - val_f_mera: 0.6982
2020-04-25 06:19:34.318937: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-25 06:19:34.415981: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-25 06:19:34.416483: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2ac3930 executing computations on platform CUDA. Devices:
2020-04-25 06:19:34.416519: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): GeForce GTX 1070, Compute Capability 6.1
2020-04-25 06:19:34.435502: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600165000 Hz
2020-04-25 06:19:34.435872: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x31880e0 executing computations on platform Host. Devices:
2020-04-25 06:19:34.435899: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2020-04-25 06:19:34.436016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.93GiB freeMemory: 7.53GiB
2020-04-25 06:19:34.436036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2020-04-25 06:19:34.436838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-25 06:19:34.436854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2020-04-25 06:19:34.436862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2020-04-25 06:19:34.436926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7327 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
Using TensorFlow backend.
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /home/polina/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/polina/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Train on 19089 samples, validate on 2120 samples
Epoch 1/500
 - 63s - loss: 0.1633 - f_mera: 0.6682 - val_loss: 0.1514 - val_f_mera: 0.6941
Epoch 2/500
 - 61s - loss: 0.1411 - f_mera: 0.7081 - val_loss: 0.1504 - val_f_mera: 0.6927
Epoch 3/500
 - 61s - loss: 0.1407 - f_mera: 0.7086 - val_loss: 0.1507 - val_f_mera: 0.6916
Epoch 4/500
 - 61s - loss: 0.1403 - f_mera: 0.7091 - val_loss: 0.1504 - val_f_mera: 0.6959
Epoch 5/500
 - 61s - loss: 0.1402 - f_mera: 0.7089 - val_loss: 0.1498 - val_f_mera: 0.6951
Epoch 6/500
 - 61s - loss: 0.1401 - f_mera: 0.7089 - val_loss: 0.1497 - val_f_mera: 0.6892
Epoch 7/500
 - 61s - loss: 0.1399 - f_mera: 0.7093 - val_loss: 0.1494 - val_f_mera: 0.6951
Epoch 8/500
 - 61s - loss: 0.1397 - f_mera: 0.7092 - val_loss: 0.1592 - val_f_mera: 0.6749
Epoch 9/500
 - 61s - loss: 0.1394 - f_mera: 0.7093 - val_loss: 0.1601 - val_f_mera: 0.6148
2020-04-25 06:30:22.109155: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-25 06:30:22.204523: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-25 06:30:22.204979: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x1fa2930 executing computations on platform CUDA. Devices:
2020-04-25 06:30:22.204999: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): GeForce GTX 1070, Compute Capability 6.1
2020-04-25 06:30:22.223509: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600165000 Hz
2020-04-25 06:30:22.223893: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x26670e0 executing computations on platform Host. Devices:
2020-04-25 06:30:22.223918: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2020-04-25 06:30:22.224049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.93GiB freeMemory: 7.53GiB
2020-04-25 06:30:22.224071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2020-04-25 06:30:22.224936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-25 06:30:22.224954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2020-04-25 06:30:22.224963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2020-04-25 06:30:22.225029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7328 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
Using TensorFlow backend.
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /home/polina/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/polina/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Train on 19089 samples, validate on 2120 samples
Epoch 1/500
 - 63s - loss: 0.1418 - f_mera: 0.7082 - val_loss: 0.1571 - val_f_mera: 0.6374
Epoch 2/500
 - 61s - loss: 0.1400 - f_mera: 0.7092 - val_loss: 0.1499 - val_f_mera: 0.6906
Epoch 3/500
 - 61s - loss: 0.1396 - f_mera: 0.7085 - val_loss: 0.1484 - val_f_mera: 0.6966
Epoch 4/500
 - 61s - loss: 0.1391 - f_mera: 0.7096 - val_loss: 0.1492 - val_f_mera: 0.6934
Epoch 5/500
 - 61s - loss: 0.1383 - f_mera: 0.7112 - val_loss: 0.1495 - val_f_mera: 0.6961
Epoch 6/500
 - 61s - loss: 0.1380 - f_mera: 0.7113 - val_loss: 0.1478 - val_f_mera: 0.6889
Epoch 7/500
 - 61s - loss: 0.1377 - f_mera: 0.7115 - val_loss: 0.1479 - val_f_mera: 0.6877
Epoch 8/500
 - 61s - loss: 0.1377 - f_mera: 0.7111 - val_loss: 0.1484 - val_f_mera: 0.6967
Epoch 9/500
 - 61s - loss: 0.1375 - f_mera: 0.7112 - val_loss: 0.1483 - val_f_mera: 0.6944
Epoch 10/500
 - 61s - loss: 0.1371 - f_mera: 0.7099 - val_loss: 0.1523 - val_f_mera: 0.6518
Epoch 11/500
 - 61s - loss: 0.1358 - f_mera: 0.7096 - val_loss: 0.1477 - val_f_mera: 0.6960
Epoch 12/500
 - 61s - loss: 0.1349 - f_mera: 0.7108 - val_loss: 0.1521 - val_f_mera: 0.6415
Epoch 13/500
 - 61s - loss: 0.1346 - f_mera: 0.7105 - val_loss: 0.1449 - val_f_mera: 0.6894
Epoch 14/500
 - 61s - loss: 0.1342 - f_mera: 0.7112 - val_loss: 0.1455 - val_f_mera: 0.6943
Epoch 15/500
 - 61s - loss: 0.1340 - f_mera: 0.7108 - val_loss: 0.1463 - val_f_mera: 0.6886
Epoch 16/500
 - 61s - loss: 0.1341 - f_mera: 0.7104 - val_loss: 0.1498 - val_f_mera: 0.6447
Epoch 17/500
 - 61s - loss: 0.1337 - f_mera: 0.7108 - val_loss: 0.1442 - val_f_mera: 0.6995
Epoch 18/500
 - 61s - loss: 0.1335 - f_mera: 0.7111 - val_loss: 0.1449 - val_f_mera: 0.6802
Epoch 19/500
 - 61s - loss: 0.1330 - f_mera: 0.7120 - val_loss: 0.1438 - val_f_mera: 0.6978
Epoch 20/500
 - 61s - loss: 0.1332 - f_mera: 0.7113 - val_loss: 0.1450 - val_f_mera: 0.6834
Epoch 21/500
 - 61s - loss: 0.1328 - f_mera: 0.7120 - val_loss: 0.1447 - val_f_mera: 0.6919
Epoch 22/500
 - 61s - loss: 0.1328 - f_mera: 0.7115 - val_loss: 0.1434 - val_f_mera: 0.6943
Epoch 23/500
 - 61s - loss: 0.1327 - f_mera: 0.7115 - val_loss: 0.1446 - val_f_mera: 0.7007
Epoch 24/500
 - 61s - loss: 0.1324 - f_mera: 0.7123 - val_loss: 0.1441 - val_f_mera: 0.6721
Epoch 25/500
 - 61s - loss: 0.1323 - f_mera: 0.7126 - val_loss: 0.1423 - val_f_mera: 0.6994
Epoch 26/500
 - 61s - loss: 0.1323 - f_mera: 0.7123 - val_loss: 0.1441 - val_f_mera: 0.6912
Epoch 27/500
 - 61s - loss: 0.1317 - f_mera: 0.7136 - val_loss: 0.1470 - val_f_mera: 0.6617
Epoch 28/500
 - 61s - loss: 0.1321 - f_mera: 0.7124 - val_loss: 0.1430 - val_f_mera: 0.6859
Epoch 29/500
 - 61s - loss: 0.1318 - f_mera: 0.7135 - val_loss: 0.1436 - val_f_mera: 0.6761
Epoch 30/500
 - 61s - loss: 0.1315 - f_mera: 0.7139 - val_loss: 0.1419 - val_f_mera: 0.7001
Epoch 31/500
 - 61s - loss: 0.1310 - f_mera: 0.7150 - val_loss: 0.1437 - val_f_mera: 0.6978
Epoch 32/500
 - 61s - loss: 0.1313 - f_mera: 0.7146 - val_loss: 0.1423 - val_f_mera: 0.6945
Epoch 33/500
 - 61s - loss: 0.1310 - f_mera: 0.7151 - val_loss: 0.1422 - val_f_mera: 0.6922
Epoch 34/500
 - 61s - loss: 0.1316 - f_mera: 0.7134 - val_loss: 0.1432 - val_f_mera: 0.6902
Epoch 35/500
 - 61s - loss: 0.1311 - f_mera: 0.7146 - val_loss: 0.1409 - val_f_mera: 0.6977
Epoch 36/500
 - 61s - loss: 0.1309 - f_mera: 0.7150 - val_loss: 0.1443 - val_f_mera: 0.6970
Epoch 37/500
 - 61s - loss: 0.1313 - f_mera: 0.7139 - val_loss: 0.1424 - val_f_mera: 0.6966
Epoch 38/500
 - 61s - loss: 0.1309 - f_mera: 0.7145 - val_loss: 0.1418 - val_f_mera: 0.6997
Epoch 39/500
 - 61s - loss: 0.1308 - f_mera: 0.7147 - val_loss: 0.1416 - val_f_mera: 0.6945
Epoch 40/500
 - 61s - loss: 0.1307 - f_mera: 0.7152 - val_loss: 0.1433 - val_f_mera: 0.6989
Epoch 41/500
 - 61s - loss: 0.1308 - f_mera: 0.7147 - val_loss: 0.1424 - val_f_mera: 0.6995
Epoch 42/500
 - 61s - loss: 0.1305 - f_mera: 0.7155 - val_loss: 0.1428 - val_f_mera: 0.6965
Epoch 43/500
 - 61s - loss: 0.1303 - f_mera: 0.7159 - val_loss: 0.1416 - val_f_mera: 0.6990
Epoch 44/500
 - 61s - loss: 0.1305 - f_mera: 0.7153 - val_loss: 0.1415 - val_f_mera: 0.6997
Epoch 45/500
 - 61s - loss: 0.1306 - f_mera: 0.7150 - val_loss: 0.1435 - val_f_mera: 0.6865
Epoch 46/500
 - 61s - loss: 0.1303 - f_mera: 0.7152 - val_loss: 0.1404 - val_f_mera: 0.6967
Epoch 47/500
 - 61s - loss: 0.1302 - f_mera: 0.7159 - val_loss: 0.1414 - val_f_mera: 0.6903
Epoch 48/500
 - 61s - loss: 0.1302 - f_mera: 0.7161 - val_loss: 0.1413 - val_f_mera: 0.6942
Epoch 49/500
 - 61s - loss: 0.1300 - f_mera: 0.7165 - val_loss: 0.1416 - val_f_mera: 0.6914
Epoch 50/500
 - 61s - loss: 0.1301 - f_mera: 0.7158 - val_loss: 0.1412 - val_f_mera: 0.7031
Epoch 51/500
 - 61s - loss: 0.1299 - f_mera: 0.7167 - val_loss: 0.1418 - val_f_mera: 0.7004
Epoch 52/500
 - 61s - loss: 0.1299 - f_mera: 0.7168 - val_loss: 0.1402 - val_f_mera: 0.6981
Epoch 53/500
 - 61s - loss: 0.1301 - f_mera: 0.7159 - val_loss: 0.1421 - val_f_mera: 0.7041
Epoch 54/500
 - 61s - loss: 0.1301 - f_mera: 0.7155 - val_loss: 0.1411 - val_f_mera: 0.6929
Epoch 55/500
 - 61s - loss: 0.1297 - f_mera: 0.7167 - val_loss: 0.1431 - val_f_mera: 0.6816
Epoch 56/500
 - 61s - loss: 0.1296 - f_mera: 0.7170 - val_loss: 0.1412 - val_f_mera: 0.6966
Epoch 57/500
 - 61s - loss: 0.1295 - f_mera: 0.7169 - val_loss: 0.1408 - val_f_mera: 0.6962
Epoch 58/500
 - 61s - loss: 0.1295 - f_mera: 0.7171 - val_loss: 0.1407 - val_f_mera: 0.6986
Epoch 59/500
 - 61s - loss: 0.1298 - f_mera: 0.7161 - val_loss: 0.1422 - val_f_mera: 0.6928
Epoch 60/500
 - 61s - loss: 0.1297 - f_mera: 0.7165 - val_loss: 0.1414 - val_f_mera: 0.6966
Epoch 61/500
 - 61s - loss: 0.1295 - f_mera: 0.7168 - val_loss: 0.1407 - val_f_mera: 0.6968
Epoch 62/500
 - 61s - loss: 0.1298 - f_mera: 0.7161 - val_loss: 0.1397 - val_f_mera: 0.7025
Epoch 63/500
 - 61s - loss: 0.1294 - f_mera: 0.7171 - val_loss: 0.1405 - val_f_mera: 0.6976
Epoch 64/500
 - 61s - loss: 0.1300 - f_mera: 0.7156 - val_loss: 0.1409 - val_f_mera: 0.7049
Epoch 65/500
 - 61s - loss: 0.1293 - f_mera: 0.7171 - val_loss: 0.1416 - val_f_mera: 0.7049
Epoch 66/500
 - 61s - loss: 0.1292 - f_mera: 0.7173 - val_loss: 0.1399 - val_f_mera: 0.7029
Epoch 67/500
 - 61s - loss: 0.1294 - f_mera: 0.7167 - val_loss: 0.1398 - val_f_mera: 0.7001
Epoch 68/500
 - 61s - loss: 0.1295 - f_mera: 0.7165 - val_loss: 0.1400 - val_f_mera: 0.7024
Epoch 69/500
 - 61s - loss: 0.1294 - f_mera: 0.7168 - val_loss: 0.1400 - val_f_mera: 0.7025
Epoch 70/500
 - 61s - loss: 0.1294 - f_mera: 0.7167 - val_loss: 0.1405 - val_f_mera: 0.6924
Epoch 71/500
 - 61s - loss: 0.1292 - f_mera: 0.7168 - val_loss: 0.1397 - val_f_mera: 0.7001
Epoch 72/500
 - 61s - loss: 0.1293 - f_mera: 0.7169 - val_loss: 0.1411 - val_f_mera: 0.6981
Epoch 73/500
 - 61s - loss: 0.1290 - f_mera: 0.7177 - val_loss: 0.1431 - val_f_mera: 0.6966
Epoch 74/500
 - 61s - loss: 0.1290 - f_mera: 0.7174 - val_loss: 0.1418 - val_f_mera: 0.6980
Epoch 75/500
 - 61s - loss: 0.1292 - f_mera: 0.7169 - val_loss: 0.1404 - val_f_mera: 0.6992
Epoch 76/500
 - 61s - loss: 0.1292 - f_mera: 0.7167 - val_loss: 0.1418 - val_f_mera: 0.6883
Epoch 77/500
 - 61s - loss: 0.1290 - f_mera: 0.7175 - val_loss: 0.1413 - val_f_mera: 0.7024
Epoch 78/500
 - 61s - loss: 0.1290 - f_mera: 0.7170 - val_loss: 0.1402 - val_f_mera: 0.7026
Epoch 79/500
 - 61s - loss: 0.1291 - f_mera: 0.7169 - val_loss: 0.1424 - val_f_mera: 0.6801
Epoch 80/500
 - 61s - loss: 0.1290 - f_mera: 0.7174 - val_loss: 0.1402 - val_f_mera: 0.7039
Epoch 81/500
 - 61s - loss: 0.1289 - f_mera: 0.7174 - val_loss: 0.1409 - val_f_mera: 0.6933
Epoch 82/500
 - 61s - loss: 0.1292 - f_mera: 0.7167 - val_loss: 0.1403 - val_f_mera: 0.6992
Epoch 83/500
 - 61s - loss: 0.1294 - f_mera: 0.7166 - val_loss: 0.1426 - val_f_mera: 0.7003
Epoch 84/500
 - 61s - loss: 0.1288 - f_mera: 0.7177 - val_loss: 0.1407 - val_f_mera: 0.6930
Epoch 85/500
 - 61s - loss: 0.1288 - f_mera: 0.7173 - val_loss: 0.1399 - val_f_mera: 0.6953
Epoch 86/500
 - 61s - loss: 0.1288 - f_mera: 0.7173 - val_loss: 0.1414 - val_f_mera: 0.6913
Epoch 87/500
 - 61s - loss: 0.1289 - f_mera: 0.7170 - val_loss: 0.1400 - val_f_mera: 0.6961
Epoch 88/500
 - 61s - loss: 0.1286 - f_mera: 0.7180 - val_loss: 0.1396 - val_f_mera: 0.7017
Epoch 89/500
 - 61s - loss: 0.1290 - f_mera: 0.7169 - val_loss: 0.1407 - val_f_mera: 0.6889
Epoch 90/500
 - 61s - loss: 0.1288 - f_mera: 0.7173 - val_loss: 0.1407 - val_f_mera: 0.7005
Epoch 91/500
 - 61s - loss: 0.1288 - f_mera: 0.7170 - val_loss: 0.1392 - val_f_mera: 0.6975
Epoch 92/500
 - 61s - loss: 0.1288 - f_mera: 0.7171 - val_loss: 0.1409 - val_f_mera: 0.6929
Epoch 93/500
 - 61s - loss: 0.1287 - f_mera: 0.7174 - val_loss: 0.1403 - val_f_mera: 0.6912
Epoch 94/500
 - 61s - loss: 0.1286 - f_mera: 0.7176 - val_loss: 0.1414 - val_f_mera: 0.6827
Epoch 95/500
 - 61s - loss: 0.1285 - f_mera: 0.7179 - val_loss: 0.1388 - val_f_mera: 0.6959
Epoch 96/500
 - 61s - loss: 0.1283 - f_mera: 0.7183 - val_loss: 0.1423 - val_f_mera: 0.6961
Epoch 97/500
 - 61s - loss: 0.1285 - f_mera: 0.7179 - val_loss: 0.1400 - val_f_mera: 0.6909
Epoch 98/500
 - 61s - loss: 0.1285 - f_mera: 0.7176 - val_loss: 0.1412 - val_f_mera: 0.6978
Epoch 99/500
 - 61s - loss: 0.1285 - f_mera: 0.7174 - val_loss: 0.1402 - val_f_mera: 0.6938
Epoch 100/500
 - 61s - loss: 0.1286 - f_mera: 0.7170 - val_loss: 0.1398 - val_f_mera: 0.6866
Epoch 101/500
 - 61s - loss: 0.1286 - f_mera: 0.7177 - val_loss: 0.1439 - val_f_mera: 0.6703
Epoch 102/500
 - 61s - loss: 0.1283 - f_mera: 0.7183 - val_loss: 0.1390 - val_f_mera: 0.6975
Epoch 103/500
 - 61s - loss: 0.1284 - f_mera: 0.7176 - val_loss: 0.1413 - val_f_mera: 0.7036
Epoch 104/500
 - 61s - loss: 0.1284 - f_mera: 0.7177 - val_loss: 0.1395 - val_f_mera: 0.7024
Epoch 105/500
 - 61s - loss: 0.1284 - f_mera: 0.7176 - val_loss: 0.1433 - val_f_mera: 0.6655
Epoch 106/500
 - 61s - loss: 0.1282 - f_mera: 0.7176 - val_loss: 0.1391 - val_f_mera: 0.6989
Epoch 107/500
 - 61s - loss: 0.1283 - f_mera: 0.7176 - val_loss: 0.1387 - val_f_mera: 0.7006
Epoch 108/500
 - 61s - loss: 0.1283 - f_mera: 0.7171 - val_loss: 0.1396 - val_f_mera: 0.7013
Epoch 109/500
 - 61s - loss: 0.1286 - f_mera: 0.7171 - val_loss: 0.1439 - val_f_mera: 0.6700
Epoch 110/500
 - 61s - loss: 0.1284 - f_mera: 0.7171 - val_loss: 0.1390 - val_f_mera: 0.7009
Epoch 111/500
 - 61s - loss: 0.1281 - f_mera: 0.7178 - val_loss: 0.1396 - val_f_mera: 0.7002
Epoch 112/500
 - 61s - loss: 0.1281 - f_mera: 0.7178 - val_loss: 0.1397 - val_f_mera: 0.7044
Epoch 113/500
 - 61s - loss: 0.1283 - f_mera: 0.7173 - val_loss: 0.1387 - val_f_mera: 0.7062
Epoch 114/500
 - 61s - loss: 0.1282 - f_mera: 0.7175 - val_loss: 0.1381 - val_f_mera: 0.7027
Epoch 115/500
 - 61s - loss: 0.1281 - f_mera: 0.7179 - val_loss: 0.1395 - val_f_mera: 0.6971
Epoch 116/500
 - 61s - loss: 0.1283 - f_mera: 0.7172 - val_loss: 0.1406 - val_f_mera: 0.7017
Epoch 117/500
 - 61s - loss: 0.1282 - f_mera: 0.7171 - val_loss: 0.1405 - val_f_mera: 0.6989
Epoch 118/500
 - 61s - loss: 0.1282 - f_mera: 0.7172 - val_loss: 0.1403 - val_f_mera: 0.7003
Epoch 119/500
 - 61s - loss: 0.1278 - f_mera: 0.7182 - val_loss: 0.1380 - val_f_mera: 0.7022
Epoch 120/500
 - 61s - loss: 0.1280 - f_mera: 0.7182 - val_loss: 0.1391 - val_f_mera: 0.7031
Epoch 121/500
 - 61s - loss: 0.1280 - f_mera: 0.7175 - val_loss: 0.1383 - val_f_mera: 0.6994
Epoch 122/500
 - 61s - loss: 0.1281 - f_mera: 0.7169 - val_loss: 0.1397 - val_f_mera: 0.7060
Epoch 123/500
 - 61s - loss: 0.1280 - f_mera: 0.7174 - val_loss: 0.1391 - val_f_mera: 0.6980
Epoch 124/500
 - 61s - loss: 0.1283 - f_mera: 0.7162 - val_loss: 0.1418 - val_f_mera: 0.6876
Epoch 125/500
 - 61s - loss: 0.1278 - f_mera: 0.7174 - val_loss: 0.1391 - val_f_mera: 0.6965
Epoch 126/500
 - 61s - loss: 0.1277 - f_mera: 0.7177 - val_loss: 0.1381 - val_f_mera: 0.7044
Epoch 127/500
 - 61s - loss: 0.1280 - f_mera: 0.7174 - val_loss: 0.1397 - val_f_mera: 0.6927
Epoch 128/500
 - 61s - loss: 0.1277 - f_mera: 0.7175 - val_loss: 0.1405 - val_f_mera: 0.7022
Epoch 129/500
 - 61s - loss: 0.1276 - f_mera: 0.7175 - val_loss: 0.1392 - val_f_mera: 0.7005
Epoch 130/500
 - 61s - loss: 0.1272 - f_mera: 0.7187 - val_loss: 0.1374 - val_f_mera: 0.7064
Epoch 131/500
 - 61s - loss: 0.1267 - f_mera: 0.7203 - val_loss: 0.1381 - val_f_mera: 0.7024
Epoch 132/500
 - 61s - loss: 0.1269 - f_mera: 0.7200 - val_loss: 0.1371 - val_f_mera: 0.7001
Epoch 133/500
 - 61s - loss: 0.1270 - f_mera: 0.7198 - val_loss: 0.1376 - val_f_mera: 0.7039
Epoch 134/500
 - 61s - loss: 0.1266 - f_mera: 0.7207 - val_loss: 0.1372 - val_f_mera: 0.7034
Epoch 135/500
 - 61s - loss: 0.1264 - f_mera: 0.7213 - val_loss: 0.1390 - val_f_mera: 0.7066
Epoch 136/500
 - 61s - loss: 0.1265 - f_mera: 0.7206 - val_loss: 0.1383 - val_f_mera: 0.6921
Epoch 137/500
 - 61s - loss: 0.1263 - f_mera: 0.7216 - val_loss: 0.1378 - val_f_mera: 0.7039
Epoch 138/500
 - 61s - loss: 0.1264 - f_mera: 0.7218 - val_loss: 0.1369 - val_f_mera: 0.6995
Epoch 139/500
 - 61s - loss: 0.1264 - f_mera: 0.7216 - val_loss: 0.1363 - val_f_mera: 0.6975
Epoch 140/500
 - 61s - loss: 0.1264 - f_mera: 0.7215 - val_loss: 0.1372 - val_f_mera: 0.6988
Epoch 141/500
 - 61s - loss: 0.1262 - f_mera: 0.7220 - val_loss: 0.1380 - val_f_mera: 0.7070
Epoch 142/500
 - 61s - loss: 0.1259 - f_mera: 0.7227 - val_loss: 0.1360 - val_f_mera: 0.7038
Epoch 143/500
 - 61s - loss: 0.1261 - f_mera: 0.7222 - val_loss: 0.1374 - val_f_mera: 0.7083
Epoch 144/500
 - 61s - loss: 0.1260 - f_mera: 0.7225 - val_loss: 0.1367 - val_f_mera: 0.6908
Epoch 145/500
 - 61s - loss: 0.1259 - f_mera: 0.7223 - val_loss: 0.1370 - val_f_mera: 0.7059
Epoch 146/500
 - 61s - loss: 0.1260 - f_mera: 0.7223 - val_loss: 0.1388 - val_f_mera: 0.7007
Epoch 147/500
 - 61s - loss: 0.1257 - f_mera: 0.7229 - val_loss: 0.1381 - val_f_mera: 0.7048
Epoch 148/500
 - 61s - loss: 0.1258 - f_mera: 0.7229 - val_loss: 0.1372 - val_f_mera: 0.7092
Epoch 149/500
 - 61s - loss: 0.1263 - f_mera: 0.7211 - val_loss: 0.1378 - val_f_mera: 0.7092
Epoch 150/500
 - 61s - loss: 0.1259 - f_mera: 0.7227 - val_loss: 0.1356 - val_f_mera: 0.7024
Epoch 151/500
 - 61s - loss: 0.1259 - f_mera: 0.7223 - val_loss: 0.1367 - val_f_mera: 0.7091
Epoch 152/500
 - 61s - loss: 0.1263 - f_mera: 0.7220 - val_loss: 0.1360 - val_f_mera: 0.7001
Epoch 153/500
 - 61s - loss: 0.1255 - f_mera: 0.7238 - val_loss: 0.1360 - val_f_mera: 0.7092
Epoch 154/500
 - 61s - loss: 0.1258 - f_mera: 0.7223 - val_loss: 0.1359 - val_f_mera: 0.7050
Epoch 155/500
 - 61s - loss: 0.1256 - f_mera: 0.7231 - val_loss: 0.1358 - val_f_mera: 0.7010
Epoch 156/500
 - 61s - loss: 0.1260 - f_mera: 0.7220 - val_loss: 0.1351 - val_f_mera: 0.7108
Epoch 157/500
 - 61s - loss: 0.1269 - f_mera: 0.7204 - val_loss: 0.1393 - val_f_mera: 0.6882
Epoch 158/500
 - 61s - loss: 0.1270 - f_mera: 0.7200 - val_loss: 0.1359 - val_f_mera: 0.6988
Epoch 159/500
 - 61s - loss: 0.1259 - f_mera: 0.7222 - val_loss: 0.1363 - val_f_mera: 0.6942
Epoch 160/500
 - 61s - loss: 0.1263 - f_mera: 0.7212 - val_loss: 0.1356 - val_f_mera: 0.6925
Epoch 161/500
 - 61s - loss: 0.1256 - f_mera: 0.7228 - val_loss: 0.1432 - val_f_mera: 0.6835
Epoch 162/500
 - 61s - loss: 0.1266 - f_mera: 0.7209 - val_loss: 0.1378 - val_f_mera: 0.7012
Epoch 163/500
 - 61s - loss: 0.1253 - f_mera: 0.7239 - val_loss: 0.1354 - val_f_mera: 0.7054
Epoch 164/500
 - 61s - loss: 0.1260 - f_mera: 0.7221 - val_loss: 0.1353 - val_f_mera: 0.7079
Epoch 165/500
 - 61s - loss: 0.1254 - f_mera: 0.7236 - val_loss: 0.1368 - val_f_mera: 0.7093
Epoch 166/500
 - 61s - loss: 0.1256 - f_mera: 0.7228 - val_loss: 0.1369 - val_f_mera: 0.7010
Epoch 167/500
 - 61s - loss: 0.1259 - f_mera: 0.7222 - val_loss: 0.1383 - val_f_mera: 0.7074
Epoch 168/500
 - 61s - loss: 0.1257 - f_mera: 0.7222 - val_loss: 0.1366 - val_f_mera: 0.6994
Epoch 169/500
 - 61s - loss: 0.1251 - f_mera: 0.7245 - val_loss: 0.1390 - val_f_mera: 0.7067
Epoch 170/500
 - 61s - loss: 0.1251 - f_mera: 0.7236 - val_loss: 0.1356 - val_f_mera: 0.7028
Epoch 171/500
 - 61s - loss: 0.1252 - f_mera: 0.7236 - val_loss: 0.1362 - val_f_mera: 0.7061
Epoch 172/500
 - 61s - loss: 0.1250 - f_mera: 0.7237 - val_loss: 0.1365 - val_f_mera: 0.7051
Epoch 173/500
 - 61s - loss: 0.1251 - f_mera: 0.7241 - val_loss: 0.1352 - val_f_mera: 0.7102
Epoch 174/500
 - 61s - loss: 0.1250 - f_mera: 0.7245 - val_loss: 0.1365 - val_f_mera: 0.7063
Epoch 175/500
 - 61s - loss: 0.1256 - f_mera: 0.7223 - val_loss: 0.1389 - val_f_mera: 0.7068
Epoch 176/500
 - 61s - loss: 0.1258 - f_mera: 0.7225 - val_loss: 0.1360 - val_f_mera: 0.7090
Epoch 177/500
 - 61s - loss: 0.1254 - f_mera: 0.7235 - val_loss: 0.1362 - val_f_mera: 0.7066
Epoch 178/500
 - 61s - loss: 0.1254 - f_mera: 0.7227 - val_loss: 0.1350 - val_f_mera: 0.7073
Epoch 179/500
 - 61s - loss: 0.1251 - f_mera: 0.7231 - val_loss: 0.1365 - val_f_mera: 0.7104
Epoch 180/500
 - 61s - loss: 0.1248 - f_mera: 0.7250 - val_loss: 0.1340 - val_f_mera: 0.7092
Epoch 181/500
 - 61s - loss: 0.1248 - f_mera: 0.7243 - val_loss: 0.1353 - val_f_mera: 0.7013
Epoch 182/500
 - 61s - loss: 0.1246 - f_mera: 0.7246 - val_loss: 0.1361 - val_f_mera: 0.6838
Epoch 183/500
 - 61s - loss: 0.1249 - f_mera: 0.7239 - val_loss: 0.1377 - val_f_mera: 0.7061
Epoch 184/500
 - 61s - loss: 0.1246 - f_mera: 0.7250 - val_loss: 0.1347 - val_f_mera: 0.7124
Epoch 185/500
 - 61s - loss: 0.1246 - f_mera: 0.7250 - val_loss: 0.1427 - val_f_mera: 0.6973
Epoch 186/500
 - 61s - loss: 0.1251 - f_mera: 0.7238 - val_loss: 0.1342 - val_f_mera: 0.7074
Epoch 187/500
 - 61s - loss: 0.1249 - f_mera: 0.7241 - val_loss: 0.1383 - val_f_mera: 0.7057
Epoch 188/500
 - 61s - loss: 0.1258 - f_mera: 0.7217 - val_loss: 0.1357 - val_f_mera: 0.6990
Epoch 189/500
 - 61s - loss: 0.1250 - f_mera: 0.7233 - val_loss: 0.1371 - val_f_mera: 0.7061
Epoch 190/500
 - 61s - loss: 0.1246 - f_mera: 0.7250 - val_loss: 0.1367 - val_f_mera: 0.7069
Epoch 191/500
 - 61s - loss: 0.1248 - f_mera: 0.7244 - val_loss: 0.1357 - val_f_mera: 0.7062
Epoch 192/500
 - 61s - loss: 0.1246 - f_mera: 0.7245 - val_loss: 0.1348 - val_f_mera: 0.7084
Epoch 193/500
 - 61s - loss: 0.1248 - f_mera: 0.7242 - val_loss: 0.1359 - val_f_mera: 0.7071
Epoch 194/500
 - 61s - loss: 0.1245 - f_mera: 0.7255 - val_loss: 0.1353 - val_f_mera: 0.7081
Epoch 195/500
 - 61s - loss: 0.1242 - f_mera: 0.7254 - val_loss: 0.2096 - val_f_mera: 0.5794
Epoch 196/500
 - 61s - loss: 0.1287 - f_mera: 0.7170 - val_loss: 0.1355 - val_f_mera: 0.7068
Epoch 197/500
 - 61s - loss: 0.1252 - f_mera: 0.7236 - val_loss: 0.1360 - val_f_mera: 0.7058
Epoch 198/500
 - 61s - loss: 0.1243 - f_mera: 0.7248 - val_loss: 0.1342 - val_f_mera: 0.7108
Epoch 199/500
 - 61s - loss: 0.1243 - f_mera: 0.7251 - val_loss: 0.1368 - val_f_mera: 0.7073
Epoch 200/500
 - 61s - loss: 0.1245 - f_mera: 0.7250 - val_loss: 0.1348 - val_f_mera: 0.6984
Epoch 201/500
 - 61s - loss: 0.1239 - f_mera: 0.7264 - val_loss: 0.1350 - val_f_mera: 0.7066
Epoch 202/500
 - 61s - loss: 0.1241 - f_mera: 0.7262 - val_loss: 0.1354 - val_f_mera: 0.7056
Epoch 203/500
 - 61s - loss: 0.1241 - f_mera: 0.7258 - val_loss: 0.1348 - val_f_mera: 0.7101
Epoch 204/500
 - 61s - loss: 0.1243 - f_mera: 0.7245 - val_loss: 0.1346 - val_f_mera: 0.7111
Epoch 205/500
 - 61s - loss: 0.1243 - f_mera: 0.7248 - val_loss: 0.1351 - val_f_mera: 0.6901
Epoch 206/500
 - 61s - loss: 0.1238 - f_mera: 0.7259 - val_loss: 0.1369 - val_f_mera: 0.7096
Epoch 207/500
 - 61s - loss: 0.1241 - f_mera: 0.7256 - val_loss: 0.1361 - val_f_mera: 0.7132
Epoch 208/500
 - 61s - loss: 0.1240 - f_mera: 0.7262 - val_loss: 0.1346 - val_f_mera: 0.7097
Epoch 209/500
 - 61s - loss: 0.1248 - f_mera: 0.7236 - val_loss: 0.1367 - val_f_mera: 0.7105
Epoch 210/500
 - 61s - loss: 0.1247 - f_mera: 0.7239 - val_loss: 0.1348 - val_f_mera: 0.7102
Epoch 211/500
 - 61s - loss: 0.1247 - f_mera: 0.7241 - val_loss: 0.1352 - val_f_mera: 0.7025
Epoch 212/500
 - 61s - loss: 0.1243 - f_mera: 0.7249 - val_loss: 0.1335 - val_f_mera: 0.7130
Epoch 213/500
 - 61s - loss: 0.1241 - f_mera: 0.7255 - val_loss: 0.1339 - val_f_mera: 0.7089
Epoch 214/500
 - 61s - loss: 0.1238 - f_mera: 0.7266 - val_loss: 0.1348 - val_f_mera: 0.7128
Epoch 215/500
 - 61s - loss: 0.1238 - f_mera: 0.7266 - val_loss: 0.1343 - val_f_mera: 0.7125
Epoch 216/500
 - 61s - loss: 0.1243 - f_mera: 0.7245 - val_loss: 0.1343 - val_f_mera: 0.7123
Epoch 217/500
 - 61s - loss: 0.1240 - f_mera: 0.7258 - val_loss: 0.1339 - val_f_mera: 0.7099
Epoch 218/500
 - 61s - loss: 0.1240 - f_mera: 0.7253 - val_loss: 0.1347 - val_f_mera: 0.7092
Epoch 219/500
 - 61s - loss: 0.1240 - f_mera: 0.7254 - val_loss: 0.1348 - val_f_mera: 0.7118
Epoch 220/500
 - 61s - loss: 0.1237 - f_mera: 0.7264 - val_loss: 0.1376 - val_f_mera: 0.7080
Epoch 221/500
 - 61s - loss: 0.1240 - f_mera: 0.7255 - val_loss: 0.1337 - val_f_mera: 0.7078
Epoch 222/500
 - 61s - loss: 0.1241 - f_mera: 0.7251 - val_loss: 0.1351 - val_f_mera: 0.7072
Epoch 223/500
 - 61s - loss: 0.1241 - f_mera: 0.7257 - val_loss: 0.1360 - val_f_mera: 0.7000
Epoch 224/500
 - 61s - loss: 0.1238 - f_mera: 0.7258 - val_loss: 0.1338 - val_f_mera: 0.7124
Epoch 225/500
 - 61s - loss: 0.1238 - f_mera: 0.7260 - val_loss: 0.1347 - val_f_mera: 0.7111
Epoch 226/500
 - 61s - loss: 0.1238 - f_mera: 0.7253 - val_loss: 0.1353 - val_f_mera: 0.7106
Epoch 227/500
 - 61s - loss: 0.1235 - f_mera: 0.7268 - val_loss: 0.1352 - val_f_mera: 0.7104
Epoch 228/500
 - 61s - loss: 0.1236 - f_mera: 0.7262 - val_loss: 0.1345 - val_f_mera: 0.7103
Epoch 229/500
 - 61s - loss: 0.1236 - f_mera: 0.7267 - val_loss: 0.1346 - val_f_mera: 0.7113
Epoch 230/500
 - 61s - loss: 0.1236 - f_mera: 0.7262 - val_loss: 0.1383 - val_f_mera: 0.7052
Epoch 231/500
 - 61s - loss: 0.1238 - f_mera: 0.7258 - val_loss: 0.1345 - val_f_mera: 0.7061
Epoch 232/500
 - 61s - loss: 0.1234 - f_mera: 0.7270 - val_loss: 0.1356 - val_f_mera: 0.7105
Epoch 233/500
 - 61s - loss: 0.1237 - f_mera: 0.7261 - val_loss: 0.1365 - val_f_mera: 0.7020
Epoch 234/500
 - 61s - loss: 0.1242 - f_mera: 0.7245 - val_loss: 0.1382 - val_f_mera: 0.7064
Epoch 235/500
 - 61s - loss: 0.1237 - f_mera: 0.7260 - val_loss: 0.1339 - val_f_mera: 0.7110
Epoch 236/500
 - 61s - loss: 0.1233 - f_mera: 0.7272 - val_loss: 0.1361 - val_f_mera: 0.7119
Epoch 237/500
 - 61s - loss: 0.1235 - f_mera: 0.7265 - val_loss: 0.1347 - val_f_mera: 0.7028
Epoch 238/500
 - 61s - loss: 0.1237 - f_mera: 0.7258 - val_loss: 0.1344 - val_f_mera: 0.7069
Epoch 239/500
 - 61s - loss: 0.1235 - f_mera: 0.7274 - val_loss: 0.1338 - val_f_mera: 0.7086
Epoch 240/500
 - 61s - loss: 0.1234 - f_mera: 0.7268 - val_loss: 0.1335 - val_f_mera: 0.7103
Epoch 241/500
 - 61s - loss: 0.1233 - f_mera: 0.7271 - val_loss: 0.1332 - val_f_mera: 0.7048
Epoch 242/500
 - 61s - loss: 0.1235 - f_mera: 0.7265 - val_loss: 0.1372 - val_f_mera: 0.7066
Epoch 243/500
 - 61s - loss: 0.1234 - f_mera: 0.7270 - val_loss: 0.1341 - val_f_mera: 0.7113
Epoch 244/500
 - 61s - loss: 0.1234 - f_mera: 0.7271 - val_loss: 0.1343 - val_f_mera: 0.7119
Epoch 245/500
 - 61s - loss: 0.1236 - f_mera: 0.7262 - val_loss: 0.1337 - val_f_mera: 0.7042
Epoch 246/500
 - 61s - loss: 0.1232 - f_mera: 0.7272 - val_loss: 0.1349 - val_f_mera: 0.7137
Epoch 247/500
 - 61s - loss: 0.1234 - f_mera: 0.7264 - val_loss: 0.1346 - val_f_mera: 0.7114
Epoch 248/500
 - 61s - loss: 0.1231 - f_mera: 0.7276 - val_loss: 0.1346 - val_f_mera: 0.7121
Epoch 249/500
 - 61s - loss: 0.1231 - f_mera: 0.7275 - val_loss: 0.1344 - val_f_mera: 0.7080
Epoch 250/500
 - 61s - loss: 0.1229 - f_mera: 0.7282 - val_loss: 0.1342 - val_f_mera: 0.7120
Epoch 251/500
 - 61s - loss: 0.1231 - f_mera: 0.7273 - val_loss: 0.1371 - val_f_mera: 0.7111
Epoch 252/500
 - 61s - loss: 0.1233 - f_mera: 0.7268 - val_loss: 0.1339 - val_f_mera: 0.7127
Epoch 253/500
 - 61s - loss: 0.1234 - f_mera: 0.7268 - val_loss: 0.1363 - val_f_mera: 0.7079
Epoch 254/500
 - 61s - loss: 0.1233 - f_mera: 0.7270 - val_loss: 0.1345 - val_f_mera: 0.7127
Epoch 255/500
 - 61s - loss: 0.1233 - f_mera: 0.7272 - val_loss: 0.1480 - val_f_mera: 0.6403
Epoch 256/500
 - 61s - loss: 0.1241 - f_mera: 0.7244 - val_loss: 0.1350 - val_f_mera: 0.7091
Epoch 257/500
 - 61s - loss: 0.1234 - f_mera: 0.7263 - val_loss: 0.1378 - val_f_mera: 0.7084
Epoch 258/500
 - 61s - loss: 0.1228 - f_mera: 0.7282 - val_loss: 0.1369 - val_f_mera: 0.7093
Epoch 259/500
 - 61s - loss: 0.1237 - f_mera: 0.7260 - val_loss: 0.1337 - val_f_mera: 0.7080
Epoch 260/500
 - 61s - loss: 0.1233 - f_mera: 0.7270 - val_loss: 0.1348 - val_f_mera: 0.7130
Epoch 261/500
 - 61s - loss: 0.1230 - f_mera: 0.7275 - val_loss: 0.1337 - val_f_mera: 0.7126
Epoch 262/500
 - 61s - loss: 0.1231 - f_mera: 0.7274 - val_loss: 0.1375 - val_f_mera: 0.7092
Epoch 263/500
 - 61s - loss: 0.1233 - f_mera: 0.7271 - val_loss: 0.1350 - val_f_mera: 0.7113
Epoch 264/500
 - 61s - loss: 0.1233 - f_mera: 0.7269 - val_loss: 0.1321 - val_f_mera: 0.7082
Epoch 265/500
 - 61s - loss: 0.1231 - f_mera: 0.7281 - val_loss: 0.1339 - val_f_mera: 0.7108
Epoch 266/500
 - 61s - loss: 0.1231 - f_mera: 0.7273 - val_loss: 0.1343 - val_f_mera: 0.7060
Epoch 267/500
 - 61s - loss: 0.1232 - f_mera: 0.7273 - val_loss: 0.1335 - val_f_mera: 0.7120
Epoch 268/500
 - 61s - loss: 0.1226 - f_mera: 0.7280 - val_loss: 0.1329 - val_f_mera: 0.7108
Epoch 269/500
 - 61s - loss: 0.1227 - f_mera: 0.7285 - val_loss: 0.1337 - val_f_mera: 0.7152
Epoch 270/500
 - 61s - loss: 0.1231 - f_mera: 0.7271 - val_loss: 0.1335 - val_f_mera: 0.7109
Epoch 271/500
 - 61s - loss: 0.1243 - f_mera: 0.7249 - val_loss: 0.1335 - val_f_mera: 0.7055
Epoch 272/500
 - 61s - loss: 0.1233 - f_mera: 0.7265 - val_loss: 0.1339 - val_f_mera: 0.7083
Epoch 273/500
 - 61s - loss: 0.1234 - f_mera: 0.7266 - val_loss: 0.1345 - val_f_mera: 0.6996
Epoch 274/500
 - 61s - loss: 0.1233 - f_mera: 0.7267 - val_loss: 0.1352 - val_f_mera: 0.7100
Epoch 275/500
 - 61s - loss: 0.1234 - f_mera: 0.7260 - val_loss: 0.1332 - val_f_mera: 0.7080
Epoch 276/500
 - 61s - loss: 0.1227 - f_mera: 0.7282 - val_loss: 0.1340 - val_f_mera: 0.6978
Epoch 277/500
 - 61s - loss: 0.1226 - f_mera: 0.7284 - val_loss: 0.1338 - val_f_mera: 0.7156
Epoch 278/500
 - 61s - loss: 0.1226 - f_mera: 0.7287 - val_loss: 0.1342 - val_f_mera: 0.7134
Epoch 279/500
 - 61s - loss: 0.1227 - f_mera: 0.7284 - val_loss: 0.1336 - val_f_mera: 0.7146
Epoch 280/500
 - 61s - loss: 0.1227 - f_mera: 0.7283 - val_loss: 0.1334 - val_f_mera: 0.7107
Epoch 281/500
 - 61s - loss: 0.1231 - f_mera: 0.7275 - val_loss: 0.1347 - val_f_mera: 0.7085
Epoch 282/500
 - 61s - loss: 0.1224 - f_mera: 0.7289 - val_loss: 0.1352 - val_f_mera: 0.7146
Epoch 283/500
 - 61s - loss: 0.1224 - f_mera: 0.7291 - val_loss: 0.1347 - val_f_mera: 0.7109
Epoch 284/500
 - 61s - loss: 0.1224 - f_mera: 0.7295 - val_loss: 0.1330 - val_f_mera: 0.7139
Epoch 285/500
 - 61s - loss: 0.1224 - f_mera: 0.7288 - val_loss: 0.1337 - val_f_mera: 0.7143
Epoch 286/500
 - 61s - loss: 0.1226 - f_mera: 0.7282 - val_loss: 0.1326 - val_f_mera: 0.7137
Epoch 287/500
 - 61s - loss: 0.1228 - f_mera: 0.7279 - val_loss: 0.1354 - val_f_mera: 0.7133
Epoch 288/500
 - 61s - loss: 0.1227 - f_mera: 0.7285 - val_loss: 0.1334 - val_f_mera: 0.7123
Epoch 289/500
 - 61s - loss: 0.1223 - f_mera: 0.7297 - val_loss: 0.1338 - val_f_mera: 0.7115
Epoch 290/500
 - 61s - loss: 0.1226 - f_mera: 0.7279 - val_loss: 0.1333 - val_f_mera: 0.7117
Epoch 291/500
 - 61s - loss: 0.1226 - f_mera: 0.7284 - val_loss: 0.1329 - val_f_mera: 0.7126
Epoch 292/500
 - 61s - loss: 0.1230 - f_mera: 0.7273 - val_loss: 0.1329 - val_f_mera: 0.7085
Epoch 293/500
 - 61s - loss: 0.1224 - f_mera: 0.7284 - val_loss: 0.1328 - val_f_mera: 0.7127
Epoch 294/500
 - 61s - loss: 0.1224 - f_mera: 0.7288 - val_loss: 0.1325 - val_f_mera: 0.7113
Epoch 295/500
 - 61s - loss: 0.1225 - f_mera: 0.7283 - val_loss: 0.1338 - val_f_mera: 0.7152
Epoch 296/500
 - 61s - loss: 0.1220 - f_mera: 0.7299 - val_loss: 0.1343 - val_f_mera: 0.7136
Epoch 297/500
 - 61s - loss: 0.1227 - f_mera: 0.7285 - val_loss: 0.1361 - val_f_mera: 0.7119
Epoch 298/500
 - 61s - loss: 0.1232 - f_mera: 0.7275 - val_loss: 0.1354 - val_f_mera: 0.7105
Epoch 299/500
 - 61s - loss: 0.1242 - f_mera: 0.7246 - val_loss: 0.1336 - val_f_mera: 0.7136
Epoch 300/500
 - 61s - loss: 0.1230 - f_mera: 0.7277 - val_loss: 0.1348 - val_f_mera: 0.7113
Epoch 301/500
 - 61s - loss: 0.1230 - f_mera: 0.7273 - val_loss: 0.1351 - val_f_mera: 0.7090
Epoch 302/500
 - 61s - loss: 0.1224 - f_mera: 0.7287 - val_loss: 0.1336 - val_f_mera: 0.7128
Epoch 303/500
 - 61s - loss: 0.1227 - f_mera: 0.7285 - val_loss: 0.1335 - val_f_mera: 0.7117
Epoch 304/500
 - 61s - loss: 0.1226 - f_mera: 0.7281 - val_loss: 0.1355 - val_f_mera: 0.7109
Epoch 305/500
 - 61s - loss: 0.1227 - f_mera: 0.7276 - val_loss: 0.1343 - val_f_mera: 0.7149
Epoch 306/500
 - 61s - loss: 0.1226 - f_mera: 0.7277 - val_loss: 0.1329 - val_f_mera: 0.7070
Epoch 307/500
 - 61s - loss: 0.1226 - f_mera: 0.7275 - val_loss: 0.1329 - val_f_mera: 0.7094
Epoch 308/500
 - 61s - loss: 0.1223 - f_mera: 0.7286 - val_loss: 0.1349 - val_f_mera: 0.7097
Epoch 309/500
 - 61s - loss: 0.1226 - f_mera: 0.7279 - val_loss: 0.1344 - val_f_mera: 0.7146
Epoch 310/500
 - 61s - loss: 0.1230 - f_mera: 0.7273 - val_loss: 0.1356 - val_f_mera: 0.7120
Epoch 311/500
 - 61s - loss: 0.1230 - f_mera: 0.7268 - val_loss: 0.1341 - val_f_mera: 0.7088
Epoch 312/500
 - 61s - loss: 0.1227 - f_mera: 0.7281 - val_loss: 0.1324 - val_f_mera: 0.7092
Epoch 313/500
 - 61s - loss: 0.1228 - f_mera: 0.7279 - val_loss: 0.1364 - val_f_mera: 0.7127
Epoch 314/500
 - 61s - loss: 0.1226 - f_mera: 0.7281 - val_loss: 0.1356 - val_f_mera: 0.7105
Epoch 315/500
 - 61s - loss: 0.1226 - f_mera: 0.7280 - val_loss: 0.1320 - val_f_mera: 0.7086
Epoch 316/500
 - 61s - loss: 0.1227 - f_mera: 0.7275 - val_loss: 0.1335 - val_f_mera: 0.7132
Epoch 317/500
 - 61s - loss: 0.1226 - f_mera: 0.7282 - val_loss: 0.1335 - val_f_mera: 0.7072
Epoch 318/500
 - 61s - loss: 0.1227 - f_mera: 0.7277 - val_loss: 0.1340 - val_f_mera: 0.7144
Epoch 319/500
 - 61s - loss: 0.1229 - f_mera: 0.7265 - val_loss: 0.1338 - val_f_mera: 0.7114
Epoch 320/500
 - 61s - loss: 0.1228 - f_mera: 0.7268 - val_loss: 0.1348 - val_f_mera: 0.7104
Epoch 321/500
 - 61s - loss: 0.1226 - f_mera: 0.7278 - val_loss: 0.1340 - val_f_mera: 0.7119
Epoch 322/500
 - 61s - loss: 0.1225 - f_mera: 0.7279 - val_loss: 0.1322 - val_f_mera: 0.7139
Epoch 323/500
 - 61s - loss: 0.1224 - f_mera: 0.7280 - val_loss: 0.1330 - val_f_mera: 0.7093
Epoch 324/500
 - 61s - loss: 0.1224 - f_mera: 0.7281 - val_loss: 0.1327 - val_f_mera: 0.7135
Epoch 325/500
 - 61s - loss: 0.1221 - f_mera: 0.7288 - val_loss: 0.1335 - val_f_mera: 0.7143
Epoch 326/500
 - 61s - loss: 0.1226 - f_mera: 0.7274 - val_loss: 0.1366 - val_f_mera: 0.7080
Epoch 327/500
 - 61s - loss: 0.1224 - f_mera: 0.7281 - val_loss: 0.1338 - val_f_mera: 0.7155
Epoch 328/500
 - 61s - loss: 0.1226 - f_mera: 0.7278 - val_loss: 0.1338 - val_f_mera: 0.7120
Epoch 329/500
 - 61s - loss: 0.1222 - f_mera: 0.7287 - val_loss: 0.1330 - val_f_mera: 0.7042
Epoch 330/500
 - 61s - loss: 0.1218 - f_mera: 0.7297 - val_loss: 0.1340 - val_f_mera: 0.7111
Epoch 331/500
 - 61s - loss: 0.1223 - f_mera: 0.7290 - val_loss: 0.1351 - val_f_mera: 0.7112
Epoch 332/500
 - 61s - loss: 0.1221 - f_mera: 0.7287 - val_loss: 0.1358 - val_f_mera: 0.7104
Epoch 333/500
 - 61s - loss: 0.1224 - f_mera: 0.7284 - val_loss: 0.1327 - val_f_mera: 0.7110
Epoch 334/500
 - 61s - loss: 0.1225 - f_mera: 0.7274 - val_loss: 0.1323 - val_f_mera: 0.7061
Epoch 335/500
 - 61s - loss: 0.1221 - f_mera: 0.7286 - val_loss: 0.1323 - val_f_mera: 0.7084
Epoch 336/500
 - 61s - loss: 0.1223 - f_mera: 0.7279 - val_loss: 0.1340 - val_f_mera: 0.7105
Epoch 337/500
 - 61s - loss: 0.1221 - f_mera: 0.7286 - val_loss: 0.1331 - val_f_mera: 0.7111
Epoch 338/500
 - 61s - loss: 0.1221 - f_mera: 0.7284 - val_loss: 0.1326 - val_f_mera: 0.7145
Epoch 339/500
 - 61s - loss: 0.1222 - f_mera: 0.7283 - val_loss: 0.1330 - val_f_mera: 0.7112
Epoch 340/500
 - 61s - loss: 0.1221 - f_mera: 0.7291 - val_loss: 0.1356 - val_f_mera: 0.7070
Epoch 341/500
 - 61s - loss: 0.1224 - f_mera: 0.7280 - val_loss: 0.1337 - val_f_mera: 0.7102
Epoch 342/500
 - 61s - loss: 0.1228 - f_mera: 0.7274 - val_loss: 0.1331 - val_f_mera: 0.7108
Epoch 343/500
 - 61s - loss: 0.1228 - f_mera: 0.7266 - val_loss: 0.1326 - val_f_mera: 0.7127
Epoch 344/500
 - 61s - loss: 0.1234 - f_mera: 0.7254 - val_loss: 0.1351 - val_f_mera: 0.7041
Epoch 345/500
 - 61s - loss: 0.1224 - f_mera: 0.7285 - val_loss: 0.1326 - val_f_mera: 0.7094
Epoch 346/500
 - 61s - loss: 0.1223 - f_mera: 0.7283 - val_loss: 0.1356 - val_f_mera: 0.7083
Epoch 347/500
 - 61s - loss: 0.1220 - f_mera: 0.7285 - val_loss: 0.1333 - val_f_mera: 0.7139
Epoch 348/500
 - 61s - loss: 0.1223 - f_mera: 0.7281 - val_loss: 0.1326 - val_f_mera: 0.7114
Epoch 349/500
 - 61s - loss: 0.1220 - f_mera: 0.7285 - val_loss: 0.1341 - val_f_mera: 0.7112
Epoch 350/500
 - 61s - loss: 0.1218 - f_mera: 0.7293 - val_loss: 0.1346 - val_f_mera: 0.7130
Epoch 351/500
 - 61s - loss: 0.1224 - f_mera: 0.7284 - val_loss: 0.1320 - val_f_mera: 0.7121
Epoch 352/500
 - 61s - loss: 0.1222 - f_mera: 0.7281 - val_loss: 0.1342 - val_f_mera: 0.7146
Epoch 353/500
 - 61s - loss: 0.1224 - f_mera: 0.7278 - val_loss: 0.1340 - val_f_mera: 0.7127
Epoch 354/500
 - 61s - loss: 0.1217 - f_mera: 0.7293 - val_loss: 0.1329 - val_f_mera: 0.7121
Epoch 355/500
 - 61s - loss: 0.1220 - f_mera: 0.7288 - val_loss: 0.1331 - val_f_mera: 0.7112
Epoch 356/500
 - 61s - loss: 0.1228 - f_mera: 0.7270 - val_loss: 0.1347 - val_f_mera: 0.7063
Epoch 357/500
 - 61s - loss: 0.1221 - f_mera: 0.7285 - val_loss: 0.1321 - val_f_mera: 0.7112
Epoch 358/500
 - 61s - loss: 0.1220 - f_mera: 0.7286 - val_loss: 0.1329 - val_f_mera: 0.7126
Epoch 359/500
 - 61s - loss: 0.1221 - f_mera: 0.7286 - val_loss: 0.1344 - val_f_mera: 0.7147
Epoch 360/500
 - 61s - loss: 0.1221 - f_mera: 0.7281 - val_loss: 0.1323 - val_f_mera: 0.7145
Epoch 361/500
 - 61s - loss: 0.1224 - f_mera: 0.7283 - val_loss: 0.1335 - val_f_mera: 0.7154
Epoch 362/500
 - 61s - loss: 0.1217 - f_mera: 0.7294 - val_loss: 0.1320 - val_f_mera: 0.7112
Epoch 363/500
 - 61s - loss: 0.1220 - f_mera: 0.7290 - val_loss: 0.1331 - val_f_mera: 0.7128
Epoch 364/500
 - 61s - loss: 0.1218 - f_mera: 0.7292 - val_loss: 0.1340 - val_f_mera: 0.7113
Epoch 365/500
 - 61s - loss: 0.1223 - f_mera: 0.7277 - val_loss: 0.1328 - val_f_mera: 0.7129
Epoch 366/500
 - 61s - loss: 0.1219 - f_mera: 0.7287 - val_loss: 0.1337 - val_f_mera: 0.7111
Epoch 367/500
 - 61s - loss: 0.1215 - f_mera: 0.7302 - val_loss: 0.1333 - val_f_mera: 0.7126
Epoch 368/500
 - 61s - loss: 0.1215 - f_mera: 0.7304 - val_loss: 0.1335 - val_f_mera: 0.7136
Epoch 369/500
 - 61s - loss: 0.1216 - f_mera: 0.7298 - val_loss: 0.1326 - val_f_mera: 0.7142
Epoch 370/500
 - 61s - loss: 0.1220 - f_mera: 0.7289 - val_loss: 0.1343 - val_f_mera: 0.7091
Epoch 371/500
 - 61s - loss: 0.1219 - f_mera: 0.7285 - val_loss: 0.1322 - val_f_mera: 0.7106
Epoch 372/500
 - 61s - loss: 0.1218 - f_mera: 0.7290 - val_loss: 0.1348 - val_f_mera: 0.7113
Epoch 373/500
 - 61s - loss: 0.1220 - f_mera: 0.7288 - val_loss: 0.1347 - val_f_mera: 0.7132
Epoch 374/500
 - 61s - loss: 0.1219 - f_mera: 0.7292 - val_loss: 0.1334 - val_f_mera: 0.7128
Epoch 375/500
 - 61s - loss: 0.1218 - f_mera: 0.7292 - val_loss: 0.1343 - val_f_mera: 0.7138
Epoch 376/500
 - 61s - loss: 0.1213 - f_mera: 0.7303 - val_loss: 0.1321 - val_f_mera: 0.7115
Epoch 377/500
 - 61s - loss: 0.1212 - f_mera: 0.7302 - val_loss: 0.1330 - val_f_mera: 0.7166
Epoch 378/500
 - 61s - loss: 0.1216 - f_mera: 0.7295 - val_loss: 0.1331 - val_f_mera: 0.7116
Epoch 379/500
 - 61s - loss: 0.1214 - f_mera: 0.7303 - val_loss: 0.1334 - val_f_mera: 0.7157
Epoch 380/500
 - 61s - loss: 0.1216 - f_mera: 0.7303 - val_loss: 0.1338 - val_f_mera: 0.7119
Epoch 381/500
 - 61s - loss: 0.1216 - f_mera: 0.7294 - val_loss: 0.1336 - val_f_mera: 0.7117
Epoch 382/500
 - 61s - loss: 0.1215 - f_mera: 0.7298 - val_loss: 0.1348 - val_f_mera: 0.7149
Epoch 383/500
 - 61s - loss: 0.1215 - f_mera: 0.7301 - val_loss: 0.1351 - val_f_mera: 0.7071
Epoch 384/500
 - 61s - loss: 0.1218 - f_mera: 0.7290 - val_loss: 0.1338 - val_f_mera: 0.7147
Epoch 385/500
 - 61s - loss: 0.1211 - f_mera: 0.7311 - val_loss: 0.1337 - val_f_mera: 0.7114
Epoch 386/500
 - 61s - loss: 0.1218 - f_mera: 0.7291 - val_loss: 0.1332 - val_f_mera: 0.7116
Epoch 387/500
 - 61s - loss: 0.1218 - f_mera: 0.7288 - val_loss: 0.1342 - val_f_mera: 0.7151
Epoch 388/500
 - 61s - loss: 0.1216 - f_mera: 0.7294 - val_loss: 0.1334 - val_f_mera: 0.7132
Epoch 389/500
 - 61s - loss: 0.1216 - f_mera: 0.7294 - val_loss: 0.1325 - val_f_mera: 0.7149
Epoch 390/500
 - 61s - loss: 0.1215 - f_mera: 0.7297 - val_loss: 0.1333 - val_f_mera: 0.7140
Epoch 391/500
 - 61s - loss: 0.1217 - f_mera: 0.7294 - val_loss: 0.1337 - val_f_mera: 0.7169
Epoch 392/500
 - 61s - loss: 0.1214 - f_mera: 0.7301 - val_loss: 0.1364 - val_f_mera: 0.7142
Epoch 393/500
 - 61s - loss: 0.1216 - f_mera: 0.7298 - val_loss: 0.1323 - val_f_mera: 0.7091
Epoch 394/500
 - 61s - loss: 0.1215 - f_mera: 0.7293 - val_loss: 0.1328 - val_f_mera: 0.7143
Epoch 395/500
 - 61s - loss: 0.1215 - f_mera: 0.7298 - val_loss: 0.1356 - val_f_mera: 0.7129
Epoch 396/500
 - 61s - loss: 0.1216 - f_mera: 0.7299 - val_loss: 0.1348 - val_f_mera: 0.7131
Epoch 397/500
 - 61s - loss: 0.1213 - f_mera: 0.7301 - val_loss: 0.1338 - val_f_mera: 0.7126
Epoch 398/500
 - 61s - loss: 0.1215 - f_mera: 0.7299 - val_loss: 0.1329 - val_f_mera: 0.7135
Epoch 399/500
 - 61s - loss: 0.1217 - f_mera: 0.7296 - val_loss: 0.1362 - val_f_mera: 0.7116
Epoch 400/500
 - 61s - loss: 0.1214 - f_mera: 0.7297 - val_loss: 0.1340 - val_f_mera: 0.7166
Epoch 401/500
 - 61s - loss: 0.1213 - f_mera: 0.7299 - val_loss: 0.1318 - val_f_mera: 0.7130
Epoch 402/500
 - 61s - loss: 0.1215 - f_mera: 0.7296 - val_loss: 0.1337 - val_f_mera: 0.7126
Epoch 403/500
 - 61s - loss: 0.1214 - f_mera: 0.7298 - val_loss: 0.1328 - val_f_mera: 0.7114
Epoch 404/500
 - 61s - loss: 0.1216 - f_mera: 0.7296 - val_loss: 0.1350 - val_f_mera: 0.7110
Epoch 405/500
 - 61s - loss: 0.1216 - f_mera: 0.7291 - val_loss: 0.1320 - val_f_mera: 0.7132
Epoch 406/500
 - 61s - loss: 0.1212 - f_mera: 0.7310 - val_loss: 0.1325 - val_f_mera: 0.7125
Epoch 407/500
 - 61s - loss: 0.1212 - f_mera: 0.7303 - val_loss: 0.1329 - val_f_mera: 0.7120
Epoch 408/500
 - 61s - loss: 0.1218 - f_mera: 0.7285 - val_loss: 0.1326 - val_f_mera: 0.7118
Epoch 409/500
 - 61s - loss: 0.1215 - f_mera: 0.7294 - val_loss: 0.1329 - val_f_mera: 0.7158
Epoch 410/500
 - 61s - loss: 0.1215 - f_mera: 0.7300 - val_loss: 0.1327 - val_f_mera: 0.7147
Epoch 411/500
 - 61s - loss: 0.1212 - f_mera: 0.7302 - val_loss: 0.1348 - val_f_mera: 0.7142
Epoch 412/500
 - 61s - loss: 0.1220 - f_mera: 0.7282 - val_loss: 0.1329 - val_f_mera: 0.7067
Epoch 413/500
 - 61s - loss: 0.1216 - f_mera: 0.7290 - val_loss: 0.1336 - val_f_mera: 0.7136
Epoch 414/500
 - 61s - loss: 0.1214 - f_mera: 0.7296 - val_loss: 0.1332 - val_f_mera: 0.7129
Epoch 415/500
 - 61s - loss: 0.1213 - f_mera: 0.7299 - val_loss: 0.1375 - val_f_mera: 0.7120
Epoch 416/500
 - 61s - loss: 0.1213 - f_mera: 0.7299 - val_loss: 0.1329 - val_f_mera: 0.7157
Epoch 417/500
 - 61s - loss: 0.1216 - f_mera: 0.7293 - val_loss: 0.1343 - val_f_mera: 0.7120
Epoch 418/500
 - 61s - loss: 0.1217 - f_mera: 0.7291 - val_loss: 0.1345 - val_f_mera: 0.7146
Epoch 419/500
 - 61s - loss: 0.1216 - f_mera: 0.7293 - val_loss: 0.1327 - val_f_mera: 0.7011
Epoch 420/500
 - 61s - loss: 0.1216 - f_mera: 0.7285 - val_loss: 0.1321 - val_f_mera: 0.7125
Epoch 421/500
 - 61s - loss: 0.1213 - f_mera: 0.7298 - val_loss: 0.1349 - val_f_mera: 0.7128
Epoch 422/500
 - 61s - loss: 0.1215 - f_mera: 0.7295 - val_loss: 0.1327 - val_f_mera: 0.7094
Epoch 423/500
 - 61s - loss: 0.1214 - f_mera: 0.7292 - val_loss: 0.1333 - val_f_mera: 0.7122
Epoch 424/500
 - 61s - loss: 0.1212 - f_mera: 0.7300 - val_loss: 0.1330 - val_f_mera: 0.7146
Epoch 425/500
 - 61s - loss: 0.1213 - f_mera: 0.7301 - val_loss: 0.1341 - val_f_mera: 0.7138
Epoch 426/500
 - 61s - loss: 0.1209 - f_mera: 0.7310 - val_loss: 0.1336 - val_f_mera: 0.7112
Epoch 427/500
 - 61s - loss: 0.1211 - f_mera: 0.7305 - val_loss: 0.1341 - val_f_mera: 0.7154
Epoch 428/500
 - 61s - loss: 0.1214 - f_mera: 0.7294 - val_loss: 0.1327 - val_f_mera: 0.7144
Epoch 429/500
 - 61s - loss: 0.1220 - f_mera: 0.7280 - val_loss: 0.1338 - val_f_mera: 0.6918
Epoch 430/500
 - 61s - loss: 0.1214 - f_mera: 0.7290 - val_loss: 0.1325 - val_f_mera: 0.7121
Epoch 431/500
 - 61s - loss: 0.1212 - f_mera: 0.7299 - val_loss: 0.1349 - val_f_mera: 0.7032
Epoch 432/500
 - 61s - loss: 0.1214 - f_mera: 0.7298 - val_loss: 0.1327 - val_f_mera: 0.7140
Epoch 433/500
 - 61s - loss: 0.1214 - f_mera: 0.7296 - val_loss: 0.1318 - val_f_mera: 0.7110
Epoch 434/500
 - 61s - loss: 0.1214 - f_mera: 0.7293 - val_loss: 0.1325 - val_f_mera: 0.7134
Epoch 435/500
 - 61s - loss: 0.1214 - f_mera: 0.7295 - val_loss: 0.1342 - val_f_mera: 0.7144
Epoch 436/500
 - 61s - loss: 0.1212 - f_mera: 0.7303 - val_loss: 0.1340 - val_f_mera: 0.7141
Epoch 437/500
 - 61s - loss: 0.1213 - f_mera: 0.7297 - val_loss: 0.1338 - val_f_mera: 0.7125
Epoch 438/500
 - 61s - loss: 0.1209 - f_mera: 0.7307 - val_loss: 0.1336 - val_f_mera: 0.7144
Epoch 439/500
 - 61s - loss: 0.1212 - f_mera: 0.7299 - val_loss: 0.1328 - val_f_mera: 0.7116
Epoch 440/500
 - 61s - loss: 0.1211 - f_mera: 0.7302 - val_loss: 0.1334 - val_f_mera: 0.7136
Epoch 441/500
 - 61s - loss: 0.1210 - f_mera: 0.7305 - val_loss: 0.1320 - val_f_mera: 0.7137
Epoch 442/500
 - 61s - loss: 0.1211 - f_mera: 0.7297 - val_loss: 0.1337 - val_f_mera: 0.7167
Epoch 443/500
 - 61s - loss: 0.1211 - f_mera: 0.7302 - val_loss: 0.1317 - val_f_mera: 0.7106
Epoch 444/500
 - 61s - loss: 0.1213 - f_mera: 0.7296 - val_loss: 0.1332 - val_f_mera: 0.7168
Epoch 445/500
 - 61s - loss: 0.1210 - f_mera: 0.7300 - val_loss: 0.1340 - val_f_mera: 0.7058
Epoch 446/500
 - 61s - loss: 0.1214 - f_mera: 0.7294 - val_loss: 0.1338 - val_f_mera: 0.7138
Epoch 447/500
 - 61s - loss: 0.1215 - f_mera: 0.7293 - val_loss: 0.1331 - val_f_mera: 0.7137
Epoch 448/500
 - 61s - loss: 0.1212 - f_mera: 0.7301 - val_loss: 0.1321 - val_f_mera: 0.7159
Epoch 449/500
 - 61s - loss: 0.1211 - f_mera: 0.7300 - val_loss: 0.1332 - val_f_mera: 0.7145
Epoch 450/500
 - 61s - loss: 0.1214 - f_mera: 0.7293 - val_loss: 0.1324 - val_f_mera: 0.7093
Epoch 451/500
 - 61s - loss: 0.1214 - f_mera: 0.7292 - val_loss: 0.1346 - val_f_mera: 0.7121
Epoch 452/500
 - 61s - loss: 0.1212 - f_mera: 0.7301 - val_loss: 0.1339 - val_f_mera: 0.7134
Epoch 453/500
 - 61s - loss: 0.1214 - f_mera: 0.7291 - val_loss: 0.1342 - val_f_mera: 0.7092
Epoch 454/500
 - 61s - loss: 0.1210 - f_mera: 0.7302 - val_loss: 0.1326 - val_f_mera: 0.7089
Epoch 455/500
 - 61s - loss: 0.1216 - f_mera: 0.7294 - val_loss: 0.1334 - val_f_mera: 0.7124
Epoch 456/500
 - 61s - loss: 0.1216 - f_mera: 0.7289 - val_loss: 0.1337 - val_f_mera: 0.7129
Epoch 457/500
 - 61s - loss: 0.1213 - f_mera: 0.7293 - val_loss: 0.1334 - val_f_mera: 0.7139
Epoch 458/500
 - 61s - loss: 0.1216 - f_mera: 0.7286 - val_loss: 0.1330 - val_f_mera: 0.7072
Epoch 459/500
 - 61s - loss: 0.1214 - f_mera: 0.7285 - val_loss: 0.1328 - val_f_mera: 0.7110
Epoch 460/500
 - 61s - loss: 0.1211 - f_mera: 0.7298 - val_loss: 0.1343 - val_f_mera: 0.7143
Epoch 461/500
 - 61s - loss: 0.1212 - f_mera: 0.7306 - val_loss: 0.1329 - val_f_mera: 0.7144
Epoch 462/500
 - 61s - loss: 0.1211 - f_mera: 0.7300 - val_loss: 0.1329 - val_f_mera: 0.7146
Epoch 463/500
 - 61s - loss: 0.1216 - f_mera: 0.7291 - val_loss: 0.1349 - val_f_mera: 0.7124
Epoch 464/500
 - 61s - loss: 0.1212 - f_mera: 0.7299 - val_loss: 0.1324 - val_f_mera: 0.7132
Epoch 465/500
 - 61s - loss: 0.1214 - f_mera: 0.7292 - val_loss: 0.1337 - val_f_mera: 0.7114
Epoch 466/500
 - 61s - loss: 0.1215 - f_mera: 0.7289 - val_loss: 0.1317 - val_f_mera: 0.7064
Epoch 467/500
 - 61s - loss: 0.1211 - f_mera: 0.7303 - val_loss: 0.1334 - val_f_mera: 0.7139
Epoch 468/500
 - 61s - loss: 0.1210 - f_mera: 0.7306 - val_loss: 0.1338 - val_f_mera: 0.7150
Epoch 469/500
 - 61s - loss: 0.1210 - f_mera: 0.7301 - val_loss: 0.1329 - val_f_mera: 0.7124
Epoch 470/500
 - 61s - loss: 0.1208 - f_mera: 0.7306 - val_loss: 0.1325 - val_f_mera: 0.7101
Epoch 471/500
 - 61s - loss: 0.1212 - f_mera: 0.7295 - val_loss: 0.1326 - val_f_mera: 0.7138
Epoch 472/500
 - 61s - loss: 0.1211 - f_mera: 0.7301 - val_loss: 0.1336 - val_f_mera: 0.7160
Epoch 473/500
 - 61s - loss: 0.1212 - f_mera: 0.7297 - val_loss: 0.1336 - val_f_mera: 0.7115
Epoch 474/500
 - 61s - loss: 0.1213 - f_mera: 0.7294 - val_loss: 0.1335 - val_f_mera: 0.7151
Epoch 475/500
 - 61s - loss: 0.1213 - f_mera: 0.7292 - val_loss: 0.1320 - val_f_mera: 0.7151
Epoch 476/500
 - 61s - loss: 0.1210 - f_mera: 0.7297 - val_loss: 0.1334 - val_f_mera: 0.7129
Epoch 477/500
 - 61s - loss: 0.1208 - f_mera: 0.7307 - val_loss: 0.1342 - val_f_mera: 0.7109
Epoch 478/500
 - 61s - loss: 0.1215 - f_mera: 0.7284 - val_loss: 0.1351 - val_f_mera: 0.7130
Epoch 479/500
 - 61s - loss: 0.1213 - f_mera: 0.7295 - val_loss: 0.1337 - val_f_mera: 0.7094
Epoch 480/500
 - 61s - loss: 0.1209 - f_mera: 0.7302 - val_loss: 0.1326 - val_f_mera: 0.7133
Epoch 481/500
 - 61s - loss: 0.1212 - f_mera: 0.7294 - val_loss: 0.1329 - val_f_mera: 0.7116
Epoch 482/500
 - 61s - loss: 0.1212 - f_mera: 0.7297 - val_loss: 0.1324 - val_f_mera: 0.7171
Epoch 483/500
 - 61s - loss: 0.1211 - f_mera: 0.7297 - val_loss: 0.1324 - val_f_mera: 0.7144
Epoch 484/500
 - 61s - loss: 0.1210 - f_mera: 0.7303 - val_loss: 0.1344 - val_f_mera: 0.7154
Epoch 485/500
 - 61s - loss: 0.1215 - f_mera: 0.7287 - val_loss: 0.1323 - val_f_mera: 0.7164
Epoch 486/500
 - 61s - loss: 0.1211 - f_mera: 0.7301 - val_loss: 0.1339 - val_f_mera: 0.7146
Epoch 487/500
 - 61s - loss: 0.1215 - f_mera: 0.7294 - val_loss: 0.1330 - val_f_mera: 0.7138
Epoch 488/500
 - 61s - loss: 0.1212 - f_mera: 0.7296 - val_loss: 0.1324 - val_f_mera: 0.7091
Epoch 489/500
 - 61s - loss: 0.1214 - f_mera: 0.7289 - val_loss: 0.1336 - val_f_mera: 0.7163
Epoch 490/500
 - 61s - loss: 0.1214 - f_mera: 0.7292 - val_loss: 0.1327 - val_f_mera: 0.7146
Epoch 491/500
 - 61s - loss: 0.1211 - f_mera: 0.7298 - val_loss: 0.1331 - val_f_mera: 0.7142
Epoch 492/500
 - 61s - loss: 0.1216 - f_mera: 0.7285 - val_loss: 0.1351 - val_f_mera: 0.7124
Epoch 493/500
 - 61s - loss: 0.1213 - f_mera: 0.7291 - val_loss: 0.1335 - val_f_mera: 0.7141
Epoch 494/500
 - 61s - loss: 0.1208 - f_mera: 0.7308 - val_loss: 0.1348 - val_f_mera: 0.7120
Epoch 495/500
 - 61s - loss: 0.1218 - f_mera: 0.7277 - val_loss: 0.1331 - val_f_mera: 0.7133
Epoch 496/500
 - 61s - loss: 0.1216 - f_mera: 0.7289 - val_loss: 0.1323 - val_f_mera: 0.7137
Epoch 497/500
 - 61s - loss: 0.1210 - f_mera: 0.7298 - val_loss: 0.1330 - val_f_mera: 0.7146
Epoch 498/500
 - 61s - loss: 0.1211 - f_mera: 0.7297 - val_loss: 0.1321 - val_f_mera: 0.7155
Epoch 499/500
 - 61s - loss: 0.1210 - f_mera: 0.7295 - val_loss: 0.1338 - val_f_mera: 0.7140
Epoch 500/500
 - 61s - loss: 0.1208 - f_mera: 0.7305 - val_loss: 0.1338 - val_f_mera: 0.7166
