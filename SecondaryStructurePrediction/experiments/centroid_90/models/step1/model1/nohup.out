2020-04-24 15:35:10.430135: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-24 15:35:10.521774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-24 15:35:10.522209: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x27f93d0 executing computations on platform CUDA. Devices:
2020-04-24 15:35:10.522226: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): GeForce GTX 1070, Compute Capability 6.1
2020-04-24 15:35:10.543515: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600165000 Hz
2020-04-24 15:35:10.543864: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2ebd590 executing computations on platform Host. Devices:
2020-04-24 15:35:10.543887: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2020-04-24 15:35:10.544006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.93GiB freeMemory: 7.54GiB
2020-04-24 15:35:10.544026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2020-04-24 15:35:10.544915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-24 15:35:10.544932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2020-04-24 15:35:10.544941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2020-04-24 15:35:10.545010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7336 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
Using TensorFlow backend.
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /home/polina/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/polina/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Train on 19089 samples, validate on 2120 samples
Epoch 1/500
 - 70s - loss: 0.0090 - f_mera: 0.5018 - val_loss: 0.0081 - val_f_mera: 0.4913
Epoch 2/500
 - 68s - loss: 0.0073 - f_mera: 0.5779 - val_loss: 0.0072 - val_f_mera: 0.5742
Epoch 3/500
 - 68s - loss: 0.0070 - f_mera: 0.5897 - val_loss: 0.0070 - val_f_mera: 0.5917
2020-04-24 15:39:36.615478: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-24 15:39:36.713617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-24 15:39:36.714132: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x145efe0 executing computations on platform CUDA. Devices:
2020-04-24 15:39:36.714155: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): GeForce GTX 1070, Compute Capability 6.1
2020-04-24 15:39:36.735518: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600165000 Hz
2020-04-24 15:39:36.735946: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x1b231c0 executing computations on platform Host. Devices:
2020-04-24 15:39:36.735975: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2020-04-24 15:39:36.736965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.93GiB freeMemory: 7.54GiB
2020-04-24 15:39:36.736993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2020-04-24 15:39:36.737882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-24 15:39:36.737900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2020-04-24 15:39:36.737910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2020-04-24 15:39:36.737988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7337 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
Using TensorFlow backend.
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /home/polina/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/polina/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Train on 19089 samples, validate on 2120 samples
Epoch 1/500
 - 104s - loss: 0.0095 - f_mera: 0.4864 - val_loss: 0.0088 - val_f_mera: 0.5190
Epoch 2/500
 - 101s - loss: 0.0077 - f_mera: 0.5628 - val_loss: 0.0074 - val_f_mera: 0.6030
Epoch 3/500
 - 101s - loss: 0.0073 - f_mera: 0.5881 - val_loss: 0.0073 - val_f_mera: 0.6071
Epoch 4/500
 - 101s - loss: 0.0072 - f_mera: 0.5937 - val_loss: 0.0074 - val_f_mera: 0.5741
Epoch 5/500
 - 102s - loss: 0.0071 - f_mera: 0.5939 - val_loss: 0.0070 - val_f_mera: 0.6101
Epoch 6/500
 - 102s - loss: 0.0069 - f_mera: 0.5981 - val_loss: 0.0069 - val_f_mera: 0.6244
Epoch 7/500
 - 102s - loss: 0.0068 - f_mera: 0.6032 - val_loss: 0.0072 - val_f_mera: 0.5479
Epoch 8/500
 - 102s - loss: 0.0068 - f_mera: 0.6027 - val_loss: 0.0068 - val_f_mera: 0.6247
Epoch 9/500
 - 102s - loss: 0.0067 - f_mera: 0.6060 - val_loss: 0.0069 - val_f_mera: 0.5805
2020-04-24 15:56:26.189355: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-24 15:56:26.280405: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-24 15:56:26.280859: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x31e13d0 executing computations on platform CUDA. Devices:
2020-04-24 15:56:26.280878: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): GeForce GTX 1070, Compute Capability 6.1
2020-04-24 15:56:26.299498: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600165000 Hz
2020-04-24 15:56:26.299841: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x38a5590 executing computations on platform Host. Devices:
2020-04-24 15:56:26.299862: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2020-04-24 15:56:26.299966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.93GiB freeMemory: 7.54GiB
2020-04-24 15:56:26.299995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2020-04-24 15:56:26.300861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-24 15:56:26.300879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2020-04-24 15:56:26.300889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2020-04-24 15:56:26.300954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7337 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
Using TensorFlow backend.
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /home/polina/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/polina/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Train on 19089 samples, validate on 2120 samples
Epoch 1/500
 - 70s - loss: 0.0317 - f_mera: 6.9569e-05 - val_loss: 0.0321 - val_f_mera: 0.0000e+00
Epoch 2/500
 - 68s - loss: 0.0317 - f_mera: 0.0000e+00 - val_loss: 0.0321 - val_f_mera: 0.0000e+00
2020-04-24 15:59:41.693322: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-24 15:59:41.791664: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-24 15:59:41.792091: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2f443d0 executing computations on platform CUDA. Devices:
2020-04-24 15:59:41.792107: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): GeForce GTX 1070, Compute Capability 6.1
2020-04-24 15:59:41.811506: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600165000 Hz
2020-04-24 15:59:41.811891: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x3608590 executing computations on platform Host. Devices:
2020-04-24 15:59:41.811916: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2020-04-24 15:59:41.812027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.93GiB freeMemory: 7.54GiB
2020-04-24 15:59:41.812047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2020-04-24 15:59:41.812908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-24 15:59:41.812933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2020-04-24 15:59:41.812942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2020-04-24 15:59:41.813006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7337 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
Using TensorFlow backend.
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /home/polina/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/polina/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Train on 38178 samples, validate on 4240 samples
Epoch 1/500
 - 139s - loss: 0.0091 - f_mera: 0.4889 - val_loss: 0.0085 - val_f_mera: 0.5210
Epoch 2/500
 - 137s - loss: 0.0081 - f_mera: 0.5248 - val_loss: 0.0074 - val_f_mera: 0.5614
Epoch 3/500
 - 137s - loss: 0.0071 - f_mera: 0.5806 - val_loss: 0.0070 - val_f_mera: 0.5948
2020-04-24 16:09:03.261864: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-24 16:09:03.355559: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-24 16:09:03.356005: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x1a913d0 executing computations on platform CUDA. Devices:
2020-04-24 16:09:03.356022: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): GeForce GTX 1070, Compute Capability 6.1
2020-04-24 16:09:03.375507: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600165000 Hz
2020-04-24 16:09:03.375916: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2155590 executing computations on platform Host. Devices:
2020-04-24 16:09:03.375940: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2020-04-24 16:09:03.376054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.93GiB freeMemory: 7.54GiB
2020-04-24 16:09:03.376074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2020-04-24 16:09:03.376934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-24 16:09:03.376951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2020-04-24 16:09:03.376959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2020-04-24 16:09:03.377026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7336 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
Using TensorFlow backend.
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /home/polina/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/polina/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Train on 19089 samples, validate on 2120 samples
Epoch 1/500
 - 70s - loss: 0.0148 - f_mera: 6.4428e-04 - val_loss: 0.0150 - val_f_mera: 0.0000e+00
Epoch 2/500
 - 68s - loss: 0.0148 - f_mera: 0.0000e+00 - val_loss: 0.0150 - val_f_mera: 0.0000e+00
2020-04-24 16:12:09.471493: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-24 16:12:09.566490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-24 16:12:09.566931: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2092fe0 executing computations on platform CUDA. Devices:
2020-04-24 16:12:09.566948: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): GeForce GTX 1070, Compute Capability 6.1
2020-04-24 16:12:09.587497: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600165000 Hz
2020-04-24 16:12:09.587871: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x27571c0 executing computations on platform Host. Devices:
2020-04-24 16:12:09.587902: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2020-04-24 16:12:09.588024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.93GiB freeMemory: 7.54GiB
2020-04-24 16:12:09.588045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2020-04-24 16:12:09.588906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-24 16:12:09.588926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2020-04-24 16:12:09.588935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2020-04-24 16:12:09.588996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7337 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
Using TensorFlow backend.
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/polina/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /home/polina/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/polina/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Train on 19089 samples, validate on 2120 samples
Epoch 1/500
 - 70s - loss: 0.0086 - f_mera: 0.4860 - val_loss: 0.0081 - val_f_mera: 0.5497
Epoch 2/500
 - 68s - loss: 0.0071 - f_mera: 0.5625 - val_loss: 0.0068 - val_f_mera: 0.6023
Epoch 3/500
 - 68s - loss: 0.0066 - f_mera: 0.5909 - val_loss: 0.0067 - val_f_mera: 0.5697
Epoch 4/500
 - 68s - loss: 0.0064 - f_mera: 0.5971 - val_loss: 0.0064 - val_f_mera: 0.6001
Epoch 5/500
 - 68s - loss: 0.0062 - f_mera: 0.6041 - val_loss: 0.0063 - val_f_mera: 0.6141
Epoch 6/500
 - 68s - loss: 0.0061 - f_mera: 0.6103 - val_loss: 0.0062 - val_f_mera: 0.6014
Epoch 7/500
 - 68s - loss: 0.0060 - f_mera: 0.6116 - val_loss: 0.0061 - val_f_mera: 0.6323
Epoch 8/500
 - 69s - loss: 0.0059 - f_mera: 0.6192 - val_loss: 0.0060 - val_f_mera: 0.6283
Epoch 9/500
 - 68s - loss: 0.0059 - f_mera: 0.6197 - val_loss: 0.0060 - val_f_mera: 0.6483
Epoch 10/500
 - 68s - loss: 0.0058 - f_mera: 0.6233 - val_loss: 0.0060 - val_f_mera: 0.6092
Epoch 11/500
 - 68s - loss: 0.0058 - f_mera: 0.6269 - val_loss: 0.0058 - val_f_mera: 0.6449
Epoch 12/500
 - 69s - loss: 0.0057 - f_mera: 0.6295 - val_loss: 0.0059 - val_f_mera: 0.6535
Epoch 13/500
 - 68s - loss: 0.0057 - f_mera: 0.6297 - val_loss: 0.0058 - val_f_mera: 0.6426
Epoch 14/500
 - 68s - loss: 0.0056 - f_mera: 0.6343 - val_loss: 0.0057 - val_f_mera: 0.6416
Epoch 15/500
 - 68s - loss: 0.0056 - f_mera: 0.6356 - val_loss: 0.0057 - val_f_mera: 0.6236
Epoch 16/500
 - 68s - loss: 0.0056 - f_mera: 0.6383 - val_loss: 0.0057 - val_f_mera: 0.6323
Epoch 17/500
 - 68s - loss: 0.0056 - f_mera: 0.6383 - val_loss: 0.0056 - val_f_mera: 0.6428
Epoch 18/500
 - 68s - loss: 0.0055 - f_mera: 0.6403 - val_loss: 0.0057 - val_f_mera: 0.6534
Epoch 19/500
 - 69s - loss: 0.0055 - f_mera: 0.6435 - val_loss: 0.0057 - val_f_mera: 0.6448
Epoch 20/500
 - 68s - loss: 0.0055 - f_mera: 0.6419 - val_loss: 0.0058 - val_f_mera: 0.6508
Epoch 21/500
 - 69s - loss: 0.0055 - f_mera: 0.6436 - val_loss: 0.0057 - val_f_mera: 0.6643
Epoch 22/500
 - 68s - loss: 0.0054 - f_mera: 0.6455 - val_loss: 0.0056 - val_f_mera: 0.6452
Epoch 23/500
 - 68s - loss: 0.0054 - f_mera: 0.6457 - val_loss: 0.0057 - val_f_mera: 0.6260
Epoch 24/500
 - 68s - loss: 0.0054 - f_mera: 0.6479 - val_loss: 0.0055 - val_f_mera: 0.6569
Epoch 25/500
 - 68s - loss: 0.0054 - f_mera: 0.6498 - val_loss: 0.0055 - val_f_mera: 0.6504
Epoch 26/500
 - 68s - loss: 0.0053 - f_mera: 0.6514 - val_loss: 0.0055 - val_f_mera: 0.6526
Epoch 27/500
 - 69s - loss: 0.0053 - f_mera: 0.6516 - val_loss: 0.0055 - val_f_mera: 0.6603
Epoch 28/500
 - 68s - loss: 0.0053 - f_mera: 0.6523 - val_loss: 0.0055 - val_f_mera: 0.6627
Epoch 29/500
 - 68s - loss: 0.0053 - f_mera: 0.6534 - val_loss: 0.0055 - val_f_mera: 0.6397
Epoch 30/500
 - 69s - loss: 0.0053 - f_mera: 0.6532 - val_loss: 0.0054 - val_f_mera: 0.6673
Epoch 31/500
 - 68s - loss: 0.0052 - f_mera: 0.6559 - val_loss: 0.0054 - val_f_mera: 0.6617
Epoch 32/500
 - 69s - loss: 0.0052 - f_mera: 0.6567 - val_loss: 0.0054 - val_f_mera: 0.6509
Epoch 33/500
 - 69s - loss: 0.0052 - f_mera: 0.6577 - val_loss: 0.0055 - val_f_mera: 0.6707
Epoch 34/500
 - 68s - loss: 0.0052 - f_mera: 0.6559 - val_loss: 0.0054 - val_f_mera: 0.6488
Epoch 35/500
 - 69s - loss: 0.0052 - f_mera: 0.6582 - val_loss: 0.0053 - val_f_mera: 0.6518
Epoch 36/500
 - 69s - loss: 0.0052 - f_mera: 0.6594 - val_loss: 0.0053 - val_f_mera: 0.6516
Epoch 37/500
 - 68s - loss: 0.0052 - f_mera: 0.6589 - val_loss: 0.0053 - val_f_mera: 0.6599
Epoch 38/500
 - 68s - loss: 0.0051 - f_mera: 0.6624 - val_loss: 0.0055 - val_f_mera: 0.6519
Epoch 39/500
 - 68s - loss: 0.0051 - f_mera: 0.6601 - val_loss: 0.0053 - val_f_mera: 0.6653
Epoch 40/500
 - 68s - loss: 0.0051 - f_mera: 0.6616 - val_loss: 0.0053 - val_f_mera: 0.6669
Epoch 41/500
 - 68s - loss: 0.0051 - f_mera: 0.6605 - val_loss: 0.0054 - val_f_mera: 0.6409
Epoch 42/500
 - 68s - loss: 0.0051 - f_mera: 0.6635 - val_loss: 0.0053 - val_f_mera: 0.6608
Epoch 43/500
 - 68s - loss: 0.0051 - f_mera: 0.6656 - val_loss: 0.0053 - val_f_mera: 0.6567
Epoch 44/500
 - 69s - loss: 0.0051 - f_mera: 0.6640 - val_loss: 0.0053 - val_f_mera: 0.6657
Epoch 45/500
 - 68s - loss: 0.0051 - f_mera: 0.6648 - val_loss: 0.0053 - val_f_mera: 0.6618
Epoch 46/500
 - 68s - loss: 0.0051 - f_mera: 0.6655 - val_loss: 0.0053 - val_f_mera: 0.6593
Epoch 47/500
 - 68s - loss: 0.0051 - f_mera: 0.6669 - val_loss: 0.0053 - val_f_mera: 0.6717
Epoch 48/500
 - 68s - loss: 0.0050 - f_mera: 0.6672 - val_loss: 0.0053 - val_f_mera: 0.6626
Epoch 49/500
 - 68s - loss: 0.0051 - f_mera: 0.6645 - val_loss: 0.0053 - val_f_mera: 0.6697
Epoch 50/500
 - 68s - loss: 0.0051 - f_mera: 0.6665 - val_loss: 0.0053 - val_f_mera: 0.6600
Epoch 51/500
 - 68s - loss: 0.0050 - f_mera: 0.6667 - val_loss: 0.0052 - val_f_mera: 0.6648
Epoch 52/500
 - 68s - loss: 0.0050 - f_mera: 0.6677 - val_loss: 0.0052 - val_f_mera: 0.6672
Epoch 53/500
 - 69s - loss: 0.0050 - f_mera: 0.6697 - val_loss: 0.0053 - val_f_mera: 0.6743
Epoch 54/500
 - 68s - loss: 0.0050 - f_mera: 0.6683 - val_loss: 0.0052 - val_f_mera: 0.6635
Epoch 55/500
 - 68s - loss: 0.0050 - f_mera: 0.6674 - val_loss: 0.0053 - val_f_mera: 0.6486
Epoch 56/500
 - 68s - loss: 0.0050 - f_mera: 0.6691 - val_loss: 0.0053 - val_f_mera: 0.6760
Epoch 57/500
 - 68s - loss: 0.0050 - f_mera: 0.6686 - val_loss: 0.0053 - val_f_mera: 0.6682
Epoch 58/500
 - 68s - loss: 0.0050 - f_mera: 0.6699 - val_loss: 0.0052 - val_f_mera: 0.6613
Epoch 59/500
 - 68s - loss: 0.0050 - f_mera: 0.6699 - val_loss: 0.0053 - val_f_mera: 0.6576
Epoch 60/500
 - 68s - loss: 0.0050 - f_mera: 0.6694 - val_loss: 0.0052 - val_f_mera: 0.6723
Epoch 61/500
 - 68s - loss: 0.0050 - f_mera: 0.6706 - val_loss: 0.0052 - val_f_mera: 0.6649
Epoch 62/500
 - 69s - loss: 0.0050 - f_mera: 0.6718 - val_loss: 0.0053 - val_f_mera: 0.6510
Epoch 63/500
 - 69s - loss: 0.0050 - f_mera: 0.6694 - val_loss: 0.0052 - val_f_mera: 0.6599
Epoch 64/500
 - 68s - loss: 0.0050 - f_mera: 0.6722 - val_loss: 0.0052 - val_f_mera: 0.6753
Epoch 65/500
 - 68s - loss: 0.0050 - f_mera: 0.6727 - val_loss: 0.0052 - val_f_mera: 0.6676
Epoch 66/500
 - 68s - loss: 0.0050 - f_mera: 0.6723 - val_loss: 0.0052 - val_f_mera: 0.6644
Epoch 67/500
 - 68s - loss: 0.0050 - f_mera: 0.6726 - val_loss: 0.0052 - val_f_mera: 0.6717
Epoch 68/500
 - 68s - loss: 0.0050 - f_mera: 0.6715 - val_loss: 0.0052 - val_f_mera: 0.6735
Epoch 69/500
 - 68s - loss: 0.0049 - f_mera: 0.6750 - val_loss: 0.0052 - val_f_mera: 0.6603
Epoch 70/500
 - 68s - loss: 0.0049 - f_mera: 0.6755 - val_loss: 0.0052 - val_f_mera: 0.6762
Epoch 71/500
 - 68s - loss: 0.0049 - f_mera: 0.6751 - val_loss: 0.0052 - val_f_mera: 0.6667
Epoch 72/500
 - 69s - loss: 0.0049 - f_mera: 0.6730 - val_loss: 0.0052 - val_f_mera: 0.6728
Epoch 73/500
 - 68s - loss: 0.0049 - f_mera: 0.6767 - val_loss: 0.0052 - val_f_mera: 0.6628
Epoch 74/500
 - 68s - loss: 0.0049 - f_mera: 0.6754 - val_loss: 0.0052 - val_f_mera: 0.6739
Epoch 75/500
 - 68s - loss: 0.0049 - f_mera: 0.6737 - val_loss: 0.0052 - val_f_mera: 0.6680
Epoch 76/500
 - 69s - loss: 0.0049 - f_mera: 0.6750 - val_loss: 0.0052 - val_f_mera: 0.6713
Epoch 77/500
 - 68s - loss: 0.0049 - f_mera: 0.6760 - val_loss: 0.0051 - val_f_mera: 0.6688
Epoch 78/500
 - 68s - loss: 0.0049 - f_mera: 0.6747 - val_loss: 0.0053 - val_f_mera: 0.6616
Epoch 79/500
 - 68s - loss: 0.0049 - f_mera: 0.6759 - val_loss: 0.0052 - val_f_mera: 0.6724
Epoch 80/500
 - 68s - loss: 0.0049 - f_mera: 0.6770 - val_loss: 0.0052 - val_f_mera: 0.6616
Epoch 81/500
 - 69s - loss: 0.0049 - f_mera: 0.6753 - val_loss: 0.0052 - val_f_mera: 0.6652
Epoch 82/500
 - 68s - loss: 0.0049 - f_mera: 0.6769 - val_loss: 0.0052 - val_f_mera: 0.6690
Epoch 83/500
 - 68s - loss: 0.0049 - f_mera: 0.6759 - val_loss: 0.0052 - val_f_mera: 0.6579
Epoch 84/500
 - 69s - loss: 0.0049 - f_mera: 0.6770 - val_loss: 0.0052 - val_f_mera: 0.6646
Epoch 85/500
 - 69s - loss: 0.0049 - f_mera: 0.6780 - val_loss: 0.0052 - val_f_mera: 0.6699
Epoch 86/500
 - 69s - loss: 0.0049 - f_mera: 0.6777 - val_loss: 0.0052 - val_f_mera: 0.6800
Epoch 87/500
 - 69s - loss: 0.0049 - f_mera: 0.6789 - val_loss: 0.0052 - val_f_mera: 0.6524
Epoch 88/500
 - 69s - loss: 0.0049 - f_mera: 0.6765 - val_loss: 0.0052 - val_f_mera: 0.6683
Epoch 89/500
 - 68s - loss: 0.0049 - f_mera: 0.6774 - val_loss: 0.0052 - val_f_mera: 0.6597
Epoch 90/500
 - 69s - loss: 0.0049 - f_mera: 0.6771 - val_loss: 0.0051 - val_f_mera: 0.6725
Epoch 91/500
 - 69s - loss: 0.0049 - f_mera: 0.6783 - val_loss: 0.0052 - val_f_mera: 0.6643
Epoch 92/500
 - 69s - loss: 0.0049 - f_mera: 0.6794 - val_loss: 0.0051 - val_f_mera: 0.6656
Epoch 93/500
 - 69s - loss: 0.0049 - f_mera: 0.6791 - val_loss: 0.0052 - val_f_mera: 0.6803
Epoch 94/500
 - 68s - loss: 0.0048 - f_mera: 0.6795 - val_loss: 0.0053 - val_f_mera: 0.6764
Epoch 95/500
 - 69s - loss: 0.0048 - f_mera: 0.6807 - val_loss: 0.0052 - val_f_mera: 0.6723
Epoch 96/500
 - 69s - loss: 0.0048 - f_mera: 0.6796 - val_loss: 0.0052 - val_f_mera: 0.6777
Epoch 97/500
 - 69s - loss: 0.0048 - f_mera: 0.6801 - val_loss: 0.0051 - val_f_mera: 0.6755
Epoch 98/500
 - 69s - loss: 0.0048 - f_mera: 0.6798 - val_loss: 0.0051 - val_f_mera: 0.6713
Epoch 99/500
 - 69s - loss: 0.0048 - f_mera: 0.6814 - val_loss: 0.0051 - val_f_mera: 0.6667
Epoch 100/500
 - 69s - loss: 0.0048 - f_mera: 0.6802 - val_loss: 0.0052 - val_f_mera: 0.6657
Epoch 101/500
 - 69s - loss: 0.0048 - f_mera: 0.6799 - val_loss: 0.0051 - val_f_mera: 0.6764
Epoch 102/500
 - 69s - loss: 0.0048 - f_mera: 0.6822 - val_loss: 0.0051 - val_f_mera: 0.6748
Epoch 103/500
 - 69s - loss: 0.0048 - f_mera: 0.6813 - val_loss: 0.0052 - val_f_mera: 0.6772
Epoch 104/500
 - 69s - loss: 0.0048 - f_mera: 0.6815 - val_loss: 0.0052 - val_f_mera: 0.6635
Epoch 105/500
 - 69s - loss: 0.0048 - f_mera: 0.6806 - val_loss: 0.0051 - val_f_mera: 0.6770
Epoch 106/500
 - 69s - loss: 0.0048 - f_mera: 0.6825 - val_loss: 0.0051 - val_f_mera: 0.6745
Epoch 107/500
 - 69s - loss: 0.0048 - f_mera: 0.6819 - val_loss: 0.0051 - val_f_mera: 0.6790
Epoch 108/500
 - 69s - loss: 0.0048 - f_mera: 0.6815 - val_loss: 0.0051 - val_f_mera: 0.6741
Epoch 109/500
 - 69s - loss: 0.0048 - f_mera: 0.6843 - val_loss: 0.0051 - val_f_mera: 0.6727
Epoch 110/500
 - 69s - loss: 0.0048 - f_mera: 0.6829 - val_loss: 0.0051 - val_f_mera: 0.6717
Epoch 111/500
 - 69s - loss: 0.0048 - f_mera: 0.6833 - val_loss: 0.0051 - val_f_mera: 0.6797
Epoch 112/500
 - 69s - loss: 0.0048 - f_mera: 0.6830 - val_loss: 0.0051 - val_f_mera: 0.6715
Epoch 113/500
 - 69s - loss: 0.0048 - f_mera: 0.6825 - val_loss: 0.0051 - val_f_mera: 0.6784
Epoch 114/500
 - 69s - loss: 0.0048 - f_mera: 0.6836 - val_loss: 0.0051 - val_f_mera: 0.6765
Epoch 115/500
 - 69s - loss: 0.0048 - f_mera: 0.6814 - val_loss: 0.0051 - val_f_mera: 0.6633
Epoch 116/500
 - 68s - loss: 0.0048 - f_mera: 0.6810 - val_loss: 0.0050 - val_f_mera: 0.6619
Epoch 117/500
 - 68s - loss: 0.0047 - f_mera: 0.6801 - val_loss: 0.0051 - val_f_mera: 0.6579
Epoch 118/500
 - 69s - loss: 0.0047 - f_mera: 0.6812 - val_loss: 0.0050 - val_f_mera: 0.6760
Epoch 119/500
 - 68s - loss: 0.0047 - f_mera: 0.6821 - val_loss: 0.0050 - val_f_mera: 0.6825
Epoch 120/500
 - 68s - loss: 0.0047 - f_mera: 0.6809 - val_loss: 0.0051 - val_f_mera: 0.6713
Epoch 121/500
 - 68s - loss: 0.0047 - f_mera: 0.6824 - val_loss: 0.0050 - val_f_mera: 0.6665
Epoch 122/500
 - 69s - loss: 0.0047 - f_mera: 0.6840 - val_loss: 0.0050 - val_f_mera: 0.6782
Epoch 123/500
 - 68s - loss: 0.0047 - f_mera: 0.6840 - val_loss: 0.0051 - val_f_mera: 0.6589
Epoch 124/500
 - 69s - loss: 0.0047 - f_mera: 0.6854 - val_loss: 0.0050 - val_f_mera: 0.6741
Epoch 125/500
 - 68s - loss: 0.0047 - f_mera: 0.6850 - val_loss: 0.0050 - val_f_mera: 0.6771
Epoch 126/500
 - 68s - loss: 0.0047 - f_mera: 0.6840 - val_loss: 0.0050 - val_f_mera: 0.6654
Epoch 127/500
 - 68s - loss: 0.0047 - f_mera: 0.6815 - val_loss: 0.0051 - val_f_mera: 0.6813
Epoch 128/500
 - 68s - loss: 0.0047 - f_mera: 0.6831 - val_loss: 0.0050 - val_f_mera: 0.6800
Epoch 129/500
 - 68s - loss: 0.0047 - f_mera: 0.6837 - val_loss: 0.0050 - val_f_mera: 0.6719
Epoch 130/500
 - 68s - loss: 0.0047 - f_mera: 0.6847 - val_loss: 0.0050 - val_f_mera: 0.6755
Epoch 131/500
 - 68s - loss: 0.0047 - f_mera: 0.6844 - val_loss: 0.0050 - val_f_mera: 0.6842
Epoch 132/500
 - 68s - loss: 0.0047 - f_mera: 0.6869 - val_loss: 0.0050 - val_f_mera: 0.6837
Epoch 133/500
 - 68s - loss: 0.0046 - f_mera: 0.6872 - val_loss: 0.0050 - val_f_mera: 0.6789
Epoch 134/500
 - 68s - loss: 0.0047 - f_mera: 0.6847 - val_loss: 0.0050 - val_f_mera: 0.6677
Epoch 135/500
 - 69s - loss: 0.0046 - f_mera: 0.6874 - val_loss: 0.0050 - val_f_mera: 0.6836
Epoch 136/500
 - 68s - loss: 0.0046 - f_mera: 0.6873 - val_loss: 0.0051 - val_f_mera: 0.6760
Epoch 137/500
 - 68s - loss: 0.0046 - f_mera: 0.6853 - val_loss: 0.0050 - val_f_mera: 0.6828
Epoch 138/500
 - 68s - loss: 0.0046 - f_mera: 0.6876 - val_loss: 0.0049 - val_f_mera: 0.6869
Epoch 139/500
 - 68s - loss: 0.0046 - f_mera: 0.6882 - val_loss: 0.0050 - val_f_mera: 0.6737
Epoch 140/500
 - 68s - loss: 0.0046 - f_mera: 0.6880 - val_loss: 0.0050 - val_f_mera: 0.6620
Epoch 141/500
 - 68s - loss: 0.0046 - f_mera: 0.6878 - val_loss: 0.0050 - val_f_mera: 0.6716
Epoch 142/500
 - 68s - loss: 0.0046 - f_mera: 0.6883 - val_loss: 0.0050 - val_f_mera: 0.6827
Epoch 143/500
 - 68s - loss: 0.0046 - f_mera: 0.6890 - val_loss: 0.0049 - val_f_mera: 0.6790
Epoch 144/500
 - 68s - loss: 0.0046 - f_mera: 0.6892 - val_loss: 0.0050 - val_f_mera: 0.6816
Epoch 145/500
 - 69s - loss: 0.0046 - f_mera: 0.6887 - val_loss: 0.0050 - val_f_mera: 0.6822
Epoch 146/500
 - 68s - loss: 0.0046 - f_mera: 0.6898 - val_loss: 0.0050 - val_f_mera: 0.6845
Epoch 147/500
 - 68s - loss: 0.0046 - f_mera: 0.6897 - val_loss: 0.0050 - val_f_mera: 0.6789
Epoch 148/500
 - 68s - loss: 0.0046 - f_mera: 0.6894 - val_loss: 0.0049 - val_f_mera: 0.6857
Epoch 149/500
 - 68s - loss: 0.0046 - f_mera: 0.6887 - val_loss: 0.0050 - val_f_mera: 0.6682
Epoch 150/500
 - 68s - loss: 0.0046 - f_mera: 0.6903 - val_loss: 0.0049 - val_f_mera: 0.6695
Epoch 151/500
 - 68s - loss: 0.0046 - f_mera: 0.6901 - val_loss: 0.0049 - val_f_mera: 0.6797
Epoch 152/500
 - 68s - loss: 0.0046 - f_mera: 0.6911 - val_loss: 0.0049 - val_f_mera: 0.6800
Epoch 153/500
 - 68s - loss: 0.0046 - f_mera: 0.6906 - val_loss: 0.0050 - val_f_mera: 0.6859
Epoch 154/500
 - 68s - loss: 0.0046 - f_mera: 0.6866 - val_loss: 0.0050 - val_f_mera: 0.6823
Epoch 155/500
 - 68s - loss: 0.0046 - f_mera: 0.6905 - val_loss: 0.0049 - val_f_mera: 0.6801
Epoch 156/500
 - 68s - loss: 0.0046 - f_mera: 0.6906 - val_loss: 0.0049 - val_f_mera: 0.6740
Epoch 157/500
 - 69s - loss: 0.0046 - f_mera: 0.6894 - val_loss: 0.0049 - val_f_mera: 0.6713
Epoch 158/500
 - 68s - loss: 0.0046 - f_mera: 0.6912 - val_loss: 0.0049 - val_f_mera: 0.6844
Epoch 159/500
 - 69s - loss: 0.0046 - f_mera: 0.6922 - val_loss: 0.0049 - val_f_mera: 0.6820
Epoch 160/500
 - 68s - loss: 0.0046 - f_mera: 0.6935 - val_loss: 0.0049 - val_f_mera: 0.6828
Epoch 161/500
 - 68s - loss: 0.0046 - f_mera: 0.6921 - val_loss: 0.0049 - val_f_mera: 0.6814
Epoch 162/500
 - 68s - loss: 0.0046 - f_mera: 0.6928 - val_loss: 0.0050 - val_f_mera: 0.6798
Epoch 163/500
 - 68s - loss: 0.0046 - f_mera: 0.6908 - val_loss: 0.0049 - val_f_mera: 0.6803
Epoch 164/500
 - 68s - loss: 0.0046 - f_mera: 0.6919 - val_loss: 0.0050 - val_f_mera: 0.6777
Epoch 165/500
 - 68s - loss: 0.0045 - f_mera: 0.6933 - val_loss: 0.0049 - val_f_mera: 0.6722
Epoch 166/500
 - 68s - loss: 0.0045 - f_mera: 0.6937 - val_loss: 0.0049 - val_f_mera: 0.6739
Epoch 167/500
 - 68s - loss: 0.0046 - f_mera: 0.6931 - val_loss: 0.0050 - val_f_mera: 0.6791
Epoch 168/500
 - 68s - loss: 0.0046 - f_mera: 0.6917 - val_loss: 0.0049 - val_f_mera: 0.6815
Epoch 169/500
 - 68s - loss: 0.0045 - f_mera: 0.6932 - val_loss: 0.0049 - val_f_mera: 0.6796
Epoch 170/500
 - 69s - loss: 0.0046 - f_mera: 0.6909 - val_loss: 0.0050 - val_f_mera: 0.6864
Epoch 171/500
 - 68s - loss: 0.0046 - f_mera: 0.6911 - val_loss: 0.0049 - val_f_mera: 0.6758
Epoch 172/500
 - 68s - loss: 0.0046 - f_mera: 0.6912 - val_loss: 0.0050 - val_f_mera: 0.6708
Epoch 173/500
 - 69s - loss: 0.0046 - f_mera: 0.6903 - val_loss: 0.0049 - val_f_mera: 0.6829
Epoch 174/500
 - 68s - loss: 0.0045 - f_mera: 0.6915 - val_loss: 0.0049 - val_f_mera: 0.6844
Epoch 175/500
 - 68s - loss: 0.0045 - f_mera: 0.6942 - val_loss: 0.0049 - val_f_mera: 0.6882
Epoch 176/500
 - 68s - loss: 0.0045 - f_mera: 0.6935 - val_loss: 0.0049 - val_f_mera: 0.6693
Epoch 177/500
 - 68s - loss: 0.0045 - f_mera: 0.6928 - val_loss: 0.0049 - val_f_mera: 0.6806
Epoch 178/500
 - 68s - loss: 0.0045 - f_mera: 0.6931 - val_loss: 0.0049 - val_f_mera: 0.6773
Epoch 179/500
 - 68s - loss: 0.0045 - f_mera: 0.6945 - val_loss: 0.0050 - val_f_mera: 0.6805
Epoch 180/500
 - 68s - loss: 0.0045 - f_mera: 0.6931 - val_loss: 0.0050 - val_f_mera: 0.6851
Epoch 181/500
 - 68s - loss: 0.0045 - f_mera: 0.6941 - val_loss: 0.0049 - val_f_mera: 0.6830
Epoch 182/500
 - 69s - loss: 0.0045 - f_mera: 0.6926 - val_loss: 0.0049 - val_f_mera: 0.6828
Epoch 183/500
 - 68s - loss: 0.0045 - f_mera: 0.6929 - val_loss: 0.0049 - val_f_mera: 0.6852
Epoch 184/500
 - 69s - loss: 0.0045 - f_mera: 0.6945 - val_loss: 0.0049 - val_f_mera: 0.6764
Epoch 185/500
 - 68s - loss: 0.0045 - f_mera: 0.6937 - val_loss: 0.0049 - val_f_mera: 0.6880
Epoch 186/500
 - 69s - loss: 0.0045 - f_mera: 0.6927 - val_loss: 0.0052 - val_f_mera: 0.6334
Epoch 187/500
 - 68s - loss: 0.0045 - f_mera: 0.6930 - val_loss: 0.0049 - val_f_mera: 0.6870
Epoch 188/500
 - 68s - loss: 0.0045 - f_mera: 0.6971 - val_loss: 0.0049 - val_f_mera: 0.6792
Epoch 189/500
 - 68s - loss: 0.0045 - f_mera: 0.6943 - val_loss: 0.0050 - val_f_mera: 0.6812
Epoch 190/500
 - 68s - loss: 0.0045 - f_mera: 0.6956 - val_loss: 0.0050 - val_f_mera: 0.6817
Epoch 191/500
 - 68s - loss: 0.0045 - f_mera: 0.6936 - val_loss: 0.0049 - val_f_mera: 0.6748
Epoch 192/500
 - 68s - loss: 0.0045 - f_mera: 0.6943 - val_loss: 0.0050 - val_f_mera: 0.6842
Epoch 193/500
 - 69s - loss: 0.0045 - f_mera: 0.6943 - val_loss: 0.0049 - val_f_mera: 0.6842
Epoch 194/500
 - 68s - loss: 0.0045 - f_mera: 0.6946 - val_loss: 0.0049 - val_f_mera: 0.6797
Epoch 195/500
 - 69s - loss: 0.0045 - f_mera: 0.6944 - val_loss: 0.0049 - val_f_mera: 0.6817
Epoch 196/500
 - 68s - loss: 0.0045 - f_mera: 0.6960 - val_loss: 0.0049 - val_f_mera: 0.6811
Epoch 197/500
 - 68s - loss: 0.0045 - f_mera: 0.6957 - val_loss: 0.0049 - val_f_mera: 0.6826
Epoch 198/500
 - 68s - loss: 0.0045 - f_mera: 0.6937 - val_loss: 0.0049 - val_f_mera: 0.6780
Epoch 199/500
 - 68s - loss: 0.0045 - f_mera: 0.6958 - val_loss: 0.0049 - val_f_mera: 0.6825
Epoch 200/500
 - 68s - loss: 0.0045 - f_mera: 0.6947 - val_loss: 0.0049 - val_f_mera: 0.6855
Epoch 201/500
 - 68s - loss: 0.0045 - f_mera: 0.6934 - val_loss: 0.0049 - val_f_mera: 0.6857
Epoch 202/500
 - 69s - loss: 0.0045 - f_mera: 0.6954 - val_loss: 0.0049 - val_f_mera: 0.6863
Epoch 203/500
 - 68s - loss: 0.0045 - f_mera: 0.6943 - val_loss: 0.0049 - val_f_mera: 0.6861
Epoch 204/500
 - 68s - loss: 0.0045 - f_mera: 0.6964 - val_loss: 0.0049 - val_f_mera: 0.6881
Epoch 205/500
 - 69s - loss: 0.0045 - f_mera: 0.6967 - val_loss: 0.0049 - val_f_mera: 0.6849
Epoch 206/500
 - 68s - loss: 0.0045 - f_mera: 0.6974 - val_loss: 0.0049 - val_f_mera: 0.6828
Epoch 207/500
 - 69s - loss: 0.0045 - f_mera: 0.6947 - val_loss: 0.0049 - val_f_mera: 0.6875
Epoch 208/500
 - 68s - loss: 0.0045 - f_mera: 0.6978 - val_loss: 0.0050 - val_f_mera: 0.6840
Epoch 209/500
 - 69s - loss: 0.0045 - f_mera: 0.6954 - val_loss: 0.0049 - val_f_mera: 0.6846
Epoch 210/500
 - 68s - loss: 0.0045 - f_mera: 0.6965 - val_loss: 0.0048 - val_f_mera: 0.6797
Epoch 211/500
 - 68s - loss: 0.0045 - f_mera: 0.6979 - val_loss: 0.0049 - val_f_mera: 0.6869
Epoch 212/500
 - 69s - loss: 0.0045 - f_mera: 0.6963 - val_loss: 0.0049 - val_f_mera: 0.6856
Epoch 213/500
 - 68s - loss: 0.0045 - f_mera: 0.6977 - val_loss: 0.0051 - val_f_mera: 0.6633
Epoch 214/500
 - 68s - loss: 0.0045 - f_mera: 0.6946 - val_loss: 0.0049 - val_f_mera: 0.6824
Epoch 215/500
 - 68s - loss: 0.0045 - f_mera: 0.6967 - val_loss: 0.0049 - val_f_mera: 0.6858
Epoch 216/500
 - 68s - loss: 0.0045 - f_mera: 0.6976 - val_loss: 0.0049 - val_f_mera: 0.6830
Epoch 217/500
 - 68s - loss: 0.0045 - f_mera: 0.6981 - val_loss: 0.0049 - val_f_mera: 0.6849
Epoch 218/500
 - 68s - loss: 0.0045 - f_mera: 0.6960 - val_loss: 0.0049 - val_f_mera: 0.6807
Epoch 219/500
 - 69s - loss: 0.0045 - f_mera: 0.6977 - val_loss: 0.0049 - val_f_mera: 0.6849
Epoch 220/500
 - 69s - loss: 0.0044 - f_mera: 0.6978 - val_loss: 0.0049 - val_f_mera: 0.6795
Epoch 221/500
 - 69s - loss: 0.0045 - f_mera: 0.6977 - val_loss: 0.0049 - val_f_mera: 0.6892
Epoch 222/500
 - 68s - loss: 0.0044 - f_mera: 0.6988 - val_loss: 0.0049 - val_f_mera: 0.6795
Epoch 223/500
 - 69s - loss: 0.0045 - f_mera: 0.6965 - val_loss: 0.0049 - val_f_mera: 0.6868
Epoch 224/500
 - 69s - loss: 0.0045 - f_mera: 0.6985 - val_loss: 0.0048 - val_f_mera: 0.6835
Epoch 225/500
 - 68s - loss: 0.0044 - f_mera: 0.6986 - val_loss: 0.0049 - val_f_mera: 0.6853
Epoch 226/500
 - 68s - loss: 0.0045 - f_mera: 0.6979 - val_loss: 0.0049 - val_f_mera: 0.6911
Epoch 227/500
 - 68s - loss: 0.0044 - f_mera: 0.6978 - val_loss: 0.0049 - val_f_mera: 0.6874
Epoch 228/500
 - 68s - loss: 0.0045 - f_mera: 0.6978 - val_loss: 0.0049 - val_f_mera: 0.6897
Epoch 229/500
 - 68s - loss: 0.0044 - f_mera: 0.6987 - val_loss: 0.0048 - val_f_mera: 0.6868
Epoch 230/500
 - 68s - loss: 0.0044 - f_mera: 0.6986 - val_loss: 0.0049 - val_f_mera: 0.6806
Epoch 231/500
 - 69s - loss: 0.0044 - f_mera: 0.6983 - val_loss: 0.0049 - val_f_mera: 0.6849
Epoch 232/500
 - 68s - loss: 0.0044 - f_mera: 0.7000 - val_loss: 0.0048 - val_f_mera: 0.6860
Epoch 233/500
 - 68s - loss: 0.0045 - f_mera: 0.6957 - val_loss: 0.0049 - val_f_mera: 0.6852
Epoch 234/500
 - 68s - loss: 0.0044 - f_mera: 0.6986 - val_loss: 0.0049 - val_f_mera: 0.6847
Epoch 235/500
 - 69s - loss: 0.0044 - f_mera: 0.6979 - val_loss: 0.0048 - val_f_mera: 0.6834
Epoch 236/500
 - 68s - loss: 0.0044 - f_mera: 0.6995 - val_loss: 0.0049 - val_f_mera: 0.6822
Epoch 237/500
 - 69s - loss: 0.0044 - f_mera: 0.6988 - val_loss: 0.0049 - val_f_mera: 0.6855
Epoch 238/500
 - 69s - loss: 0.0044 - f_mera: 0.6995 - val_loss: 0.0050 - val_f_mera: 0.6824
Epoch 239/500
 - 69s - loss: 0.0044 - f_mera: 0.6988 - val_loss: 0.0050 - val_f_mera: 0.6650
Epoch 240/500
 - 69s - loss: 0.0044 - f_mera: 0.6992 - val_loss: 0.0049 - val_f_mera: 0.6766
Epoch 241/500
 - 69s - loss: 0.0044 - f_mera: 0.7009 - val_loss: 0.0049 - val_f_mera: 0.6824
Epoch 242/500
 - 69s - loss: 0.0044 - f_mera: 0.6996 - val_loss: 0.0049 - val_f_mera: 0.6891
Epoch 243/500
 - 69s - loss: 0.0044 - f_mera: 0.6996 - val_loss: 0.0048 - val_f_mera: 0.6798
Epoch 244/500
 - 68s - loss: 0.0044 - f_mera: 0.6994 - val_loss: 0.0048 - val_f_mera: 0.6874
Epoch 245/500
 - 69s - loss: 0.0044 - f_mera: 0.6976 - val_loss: 0.0049 - val_f_mera: 0.6838
Epoch 246/500
 - 68s - loss: 0.0044 - f_mera: 0.6988 - val_loss: 0.0049 - val_f_mera: 0.6800
Epoch 247/500
 - 69s - loss: 0.0044 - f_mera: 0.7012 - val_loss: 0.0049 - val_f_mera: 0.6835
Epoch 248/500
 - 68s - loss: 0.0044 - f_mera: 0.7011 - val_loss: 0.0048 - val_f_mera: 0.6810
Epoch 249/500
 - 69s - loss: 0.0044 - f_mera: 0.7001 - val_loss: 0.0048 - val_f_mera: 0.6886
Epoch 250/500
 - 69s - loss: 0.0044 - f_mera: 0.7000 - val_loss: 0.0049 - val_f_mera: 0.6871
Epoch 251/500
 - 68s - loss: 0.0044 - f_mera: 0.7008 - val_loss: 0.0048 - val_f_mera: 0.6873
Epoch 252/500
 - 69s - loss: 0.0044 - f_mera: 0.7012 - val_loss: 0.0048 - val_f_mera: 0.6884
Epoch 253/500
 - 68s - loss: 0.0044 - f_mera: 0.7020 - val_loss: 0.0048 - val_f_mera: 0.6825
Epoch 254/500
 - 68s - loss: 0.0044 - f_mera: 0.7010 - val_loss: 0.0049 - val_f_mera: 0.6899
Epoch 255/500
 - 69s - loss: 0.0044 - f_mera: 0.7013 - val_loss: 0.0049 - val_f_mera: 0.6891
Epoch 256/500
 - 69s - loss: 0.0044 - f_mera: 0.7009 - val_loss: 0.0049 - val_f_mera: 0.6787
Epoch 257/500
 - 68s - loss: 0.0044 - f_mera: 0.7007 - val_loss: 0.0048 - val_f_mera: 0.6846
Epoch 258/500
 - 68s - loss: 0.0044 - f_mera: 0.7016 - val_loss: 0.0049 - val_f_mera: 0.6875
Epoch 259/500
 - 69s - loss: 0.0044 - f_mera: 0.7029 - val_loss: 0.0048 - val_f_mera: 0.6890
Epoch 260/500
 - 68s - loss: 0.0044 - f_mera: 0.7030 - val_loss: 0.0048 - val_f_mera: 0.6877
Epoch 261/500
 - 69s - loss: 0.0044 - f_mera: 0.7040 - val_loss: 0.0050 - val_f_mera: 0.6884
Epoch 262/500
 - 69s - loss: 0.0044 - f_mera: 0.7024 - val_loss: 0.0049 - val_f_mera: 0.6867
Epoch 263/500
 - 69s - loss: 0.0044 - f_mera: 0.7024 - val_loss: 0.0048 - val_f_mera: 0.6865
Epoch 264/500
 - 68s - loss: 0.0044 - f_mera: 0.7024 - val_loss: 0.0049 - val_f_mera: 0.6913
Epoch 265/500
 - 68s - loss: 0.0044 - f_mera: 0.7018 - val_loss: 0.0048 - val_f_mera: 0.6816
Epoch 266/500
 - 68s - loss: 0.0044 - f_mera: 0.7027 - val_loss: 0.0049 - val_f_mera: 0.6779
Epoch 267/500
 - 69s - loss: 0.0044 - f_mera: 0.7021 - val_loss: 0.0049 - val_f_mera: 0.6865
Epoch 268/500
 - 68s - loss: 0.0044 - f_mera: 0.7011 - val_loss: 0.0048 - val_f_mera: 0.6797
Epoch 269/500
 - 68s - loss: 0.0044 - f_mera: 0.7014 - val_loss: 0.0048 - val_f_mera: 0.6908
Epoch 270/500
 - 69s - loss: 0.0044 - f_mera: 0.7006 - val_loss: 0.0048 - val_f_mera: 0.6828
Epoch 271/500
 - 69s - loss: 0.0044 - f_mera: 0.7029 - val_loss: 0.0050 - val_f_mera: 0.6878
Epoch 272/500
 - 69s - loss: 0.0044 - f_mera: 0.7024 - val_loss: 0.0048 - val_f_mera: 0.6876
Epoch 273/500
 - 68s - loss: 0.0044 - f_mera: 0.7025 - val_loss: 0.0048 - val_f_mera: 0.6874
Epoch 274/500
 - 69s - loss: 0.0044 - f_mera: 0.7040 - val_loss: 0.0049 - val_f_mera: 0.6900
Epoch 275/500
 - 68s - loss: 0.0044 - f_mera: 0.7035 - val_loss: 0.0048 - val_f_mera: 0.6881
Epoch 276/500
 - 68s - loss: 0.0044 - f_mera: 0.7037 - val_loss: 0.0048 - val_f_mera: 0.6900
Epoch 277/500
 - 68s - loss: 0.0044 - f_mera: 0.7030 - val_loss: 0.0048 - val_f_mera: 0.6873
Epoch 278/500
 - 68s - loss: 0.0044 - f_mera: 0.7023 - val_loss: 0.0048 - val_f_mera: 0.6880
Epoch 279/500
 - 68s - loss: 0.0044 - f_mera: 0.7027 - val_loss: 0.0048 - val_f_mera: 0.6875
Epoch 280/500
 - 68s - loss: 0.0044 - f_mera: 0.7024 - val_loss: 0.0048 - val_f_mera: 0.6841
Epoch 281/500
 - 68s - loss: 0.0044 - f_mera: 0.7036 - val_loss: 0.0048 - val_f_mera: 0.6782
Epoch 282/500
 - 69s - loss: 0.0044 - f_mera: 0.7018 - val_loss: 0.0049 - val_f_mera: 0.6780
Epoch 283/500
 - 68s - loss: 0.0044 - f_mera: 0.7016 - val_loss: 0.0048 - val_f_mera: 0.6886
Epoch 284/500
 - 68s - loss: 0.0044 - f_mera: 0.7039 - val_loss: 0.0049 - val_f_mera: 0.6881
Epoch 285/500
 - 68s - loss: 0.0044 - f_mera: 0.7050 - val_loss: 0.0049 - val_f_mera: 0.6895
Epoch 286/500
 - 69s - loss: 0.0044 - f_mera: 0.7030 - val_loss: 0.0048 - val_f_mera: 0.6852
Epoch 287/500
 - 69s - loss: 0.0044 - f_mera: 0.7029 - val_loss: 0.0048 - val_f_mera: 0.6901
Epoch 288/500
 - 68s - loss: 0.0044 - f_mera: 0.7039 - val_loss: 0.0048 - val_f_mera: 0.6883
Epoch 289/500
 - 68s - loss: 0.0044 - f_mera: 0.7036 - val_loss: 0.0048 - val_f_mera: 0.6915
Epoch 290/500
 - 68s - loss: 0.0044 - f_mera: 0.7053 - val_loss: 0.0048 - val_f_mera: 0.6892
Epoch 291/500
 - 68s - loss: 0.0044 - f_mera: 0.7036 - val_loss: 0.0048 - val_f_mera: 0.6892
Epoch 292/500
 - 68s - loss: 0.0044 - f_mera: 0.7042 - val_loss: 0.0048 - val_f_mera: 0.6794
Epoch 293/500
 - 69s - loss: 0.0043 - f_mera: 0.7042 - val_loss: 0.0048 - val_f_mera: 0.6870
Epoch 294/500
 - 69s - loss: 0.0043 - f_mera: 0.7046 - val_loss: 0.0048 - val_f_mera: 0.6871
Epoch 295/500
 - 69s - loss: 0.0044 - f_mera: 0.7029 - val_loss: 0.0048 - val_f_mera: 0.6826
Epoch 296/500
 - 68s - loss: 0.0044 - f_mera: 0.7030 - val_loss: 0.0048 - val_f_mera: 0.6903
Epoch 297/500
 - 68s - loss: 0.0043 - f_mera: 0.7043 - val_loss: 0.0048 - val_f_mera: 0.6879
Epoch 298/500
 - 68s - loss: 0.0043 - f_mera: 0.7048 - val_loss: 0.0048 - val_f_mera: 0.6837
Epoch 299/500
 - 68s - loss: 0.0043 - f_mera: 0.7036 - val_loss: 0.0049 - val_f_mera: 0.6837
Epoch 300/500
 - 68s - loss: 0.0043 - f_mera: 0.7037 - val_loss: 0.0049 - val_f_mera: 0.6877
Epoch 301/500
 - 69s - loss: 0.0043 - f_mera: 0.7052 - val_loss: 0.0049 - val_f_mera: 0.6881
Epoch 302/500
 - 69s - loss: 0.0043 - f_mera: 0.7041 - val_loss: 0.0048 - val_f_mera: 0.6916
Epoch 303/500
 - 69s - loss: 0.0043 - f_mera: 0.7045 - val_loss: 0.0048 - val_f_mera: 0.6887
Epoch 304/500
 - 68s - loss: 0.0043 - f_mera: 0.7056 - val_loss: 0.0048 - val_f_mera: 0.6912
Epoch 305/500
 - 69s - loss: 0.0043 - f_mera: 0.7064 - val_loss: 0.0049 - val_f_mera: 0.6919
Epoch 306/500
 - 68s - loss: 0.0044 - f_mera: 0.7018 - val_loss: 0.0049 - val_f_mera: 0.6790
Epoch 307/500
 - 68s - loss: 0.0043 - f_mera: 0.7040 - val_loss: 0.0048 - val_f_mera: 0.6874
Epoch 308/500
 - 68s - loss: 0.0043 - f_mera: 0.7055 - val_loss: 0.0049 - val_f_mera: 0.6900
Epoch 309/500
 - 68s - loss: 0.0044 - f_mera: 0.7031 - val_loss: 0.0048 - val_f_mera: 0.6886
Epoch 310/500
 - 68s - loss: 0.0044 - f_mera: 0.7040 - val_loss: 0.0048 - val_f_mera: 0.6869
Epoch 311/500
 - 69s - loss: 0.0043 - f_mera: 0.7053 - val_loss: 0.0048 - val_f_mera: 0.6880
Epoch 312/500
 - 68s - loss: 0.0043 - f_mera: 0.7058 - val_loss: 0.0048 - val_f_mera: 0.6877
Epoch 313/500
 - 68s - loss: 0.0044 - f_mera: 0.7038 - val_loss: 0.0048 - val_f_mera: 0.6909
Epoch 314/500
 - 68s - loss: 0.0043 - f_mera: 0.7041 - val_loss: 0.0049 - val_f_mera: 0.6929
Epoch 315/500
 - 68s - loss: 0.0043 - f_mera: 0.7054 - val_loss: 0.0048 - val_f_mera: 0.6883
Epoch 316/500
 - 68s - loss: 0.0043 - f_mera: 0.7058 - val_loss: 0.0048 - val_f_mera: 0.6857
Epoch 317/500
 - 68s - loss: 0.0043 - f_mera: 0.7061 - val_loss: 0.0048 - val_f_mera: 0.6859
Epoch 318/500
 - 68s - loss: 0.0043 - f_mera: 0.7061 - val_loss: 0.0048 - val_f_mera: 0.6874
Epoch 319/500
 - 68s - loss: 0.0043 - f_mera: 0.7047 - val_loss: 0.0049 - val_f_mera: 0.6888
Epoch 320/500
 - 68s - loss: 0.0043 - f_mera: 0.7052 - val_loss: 0.0048 - val_f_mera: 0.6895
Epoch 321/500
 - 68s - loss: 0.0043 - f_mera: 0.7070 - val_loss: 0.0048 - val_f_mera: 0.6879
Epoch 322/500
 - 68s - loss: 0.0043 - f_mera: 0.7077 - val_loss: 0.0048 - val_f_mera: 0.6896
Epoch 323/500
 - 68s - loss: 0.0043 - f_mera: 0.7077 - val_loss: 0.0048 - val_f_mera: 0.6889
Epoch 324/500
 - 68s - loss: 0.0043 - f_mera: 0.7085 - val_loss: 0.0048 - val_f_mera: 0.6890
Epoch 325/500
 - 68s - loss: 0.0043 - f_mera: 0.7057 - val_loss: 0.0048 - val_f_mera: 0.6846
Epoch 326/500
 - 68s - loss: 0.0043 - f_mera: 0.7061 - val_loss: 0.0048 - val_f_mera: 0.6899
Epoch 327/500
 - 68s - loss: 0.0043 - f_mera: 0.7048 - val_loss: 0.0048 - val_f_mera: 0.6829
Epoch 328/500
 - 68s - loss: 0.0043 - f_mera: 0.7057 - val_loss: 0.0048 - val_f_mera: 0.6821
Epoch 329/500
 - 68s - loss: 0.0043 - f_mera: 0.7064 - val_loss: 0.0048 - val_f_mera: 0.6876
Epoch 330/500
 - 68s - loss: 0.0043 - f_mera: 0.7082 - val_loss: 0.0048 - val_f_mera: 0.6844
Epoch 331/500
 - 69s - loss: 0.0043 - f_mera: 0.7080 - val_loss: 0.0048 - val_f_mera: 0.6901
Epoch 332/500
 - 68s - loss: 0.0043 - f_mera: 0.7081 - val_loss: 0.0048 - val_f_mera: 0.6899
Epoch 333/500
 - 68s - loss: 0.0043 - f_mera: 0.7074 - val_loss: 0.0048 - val_f_mera: 0.6861
Epoch 334/500
 - 68s - loss: 0.0043 - f_mera: 0.7084 - val_loss: 0.0048 - val_f_mera: 0.6906
Epoch 335/500
 - 68s - loss: 0.0043 - f_mera: 0.7075 - val_loss: 0.0049 - val_f_mera: 0.6907
Epoch 336/500
 - 68s - loss: 0.0043 - f_mera: 0.7085 - val_loss: 0.0048 - val_f_mera: 0.6892
Epoch 337/500
 - 68s - loss: 0.0043 - f_mera: 0.7067 - val_loss: 0.0048 - val_f_mera: 0.6901
Epoch 338/500
 - 69s - loss: 0.0043 - f_mera: 0.7080 - val_loss: 0.0048 - val_f_mera: 0.6880
Epoch 339/500
 - 68s - loss: 0.0043 - f_mera: 0.7081 - val_loss: 0.0048 - val_f_mera: 0.6849
Epoch 340/500
 - 68s - loss: 0.0043 - f_mera: 0.7082 - val_loss: 0.0048 - val_f_mera: 0.6915
Epoch 341/500
 - 68s - loss: 0.0043 - f_mera: 0.7085 - val_loss: 0.0048 - val_f_mera: 0.6891
Epoch 342/500
 - 68s - loss: 0.0043 - f_mera: 0.7097 - val_loss: 0.0048 - val_f_mera: 0.6859
Epoch 343/500
 - 69s - loss: 0.0043 - f_mera: 0.7080 - val_loss: 0.0048 - val_f_mera: 0.6876
Epoch 344/500
 - 68s - loss: 0.0043 - f_mera: 0.7071 - val_loss: 0.0048 - val_f_mera: 0.6905
Epoch 345/500
 - 68s - loss: 0.0044 - f_mera: 0.7026 - val_loss: 0.0048 - val_f_mera: 0.6866
Epoch 346/500
 - 68s - loss: 0.0043 - f_mera: 0.7057 - val_loss: 0.0048 - val_f_mera: 0.6893
Epoch 347/500
 - 68s - loss: 0.0043 - f_mera: 0.7080 - val_loss: 0.0048 - val_f_mera: 0.6893
Epoch 348/500
 - 68s - loss: 0.0043 - f_mera: 0.7089 - val_loss: 0.0049 - val_f_mera: 0.6924
Epoch 349/500
 - 68s - loss: 0.0043 - f_mera: 0.7093 - val_loss: 0.0049 - val_f_mera: 0.6921
Epoch 350/500
 - 68s - loss: 0.0043 - f_mera: 0.7084 - val_loss: 0.0048 - val_f_mera: 0.6905
Epoch 351/500
 - 68s - loss: 0.0043 - f_mera: 0.7083 - val_loss: 0.0048 - val_f_mera: 0.6895
Epoch 352/500
 - 68s - loss: 0.0043 - f_mera: 0.7086 - val_loss: 0.0048 - val_f_mera: 0.6923
Epoch 353/500
 - 68s - loss: 0.0043 - f_mera: 0.7088 - val_loss: 0.0048 - val_f_mera: 0.6874
Epoch 354/500
 - 68s - loss: 0.0043 - f_mera: 0.7088 - val_loss: 0.0048 - val_f_mera: 0.6880
Epoch 355/500
 - 68s - loss: 0.0043 - f_mera: 0.7084 - val_loss: 0.0048 - val_f_mera: 0.6905
Epoch 356/500
 - 69s - loss: 0.0043 - f_mera: 0.7097 - val_loss: 0.0049 - val_f_mera: 0.6860
Epoch 357/500
 - 68s - loss: 0.0043 - f_mera: 0.7081 - val_loss: 0.0048 - val_f_mera: 0.6846
Epoch 358/500
 - 68s - loss: 0.0043 - f_mera: 0.7081 - val_loss: 0.0048 - val_f_mera: 0.6849
Epoch 359/500
 - 68s - loss: 0.0043 - f_mera: 0.7099 - val_loss: 0.0049 - val_f_mera: 0.6926
Epoch 360/500
 - 69s - loss: 0.0043 - f_mera: 0.7086 - val_loss: 0.0048 - val_f_mera: 0.6904
Epoch 361/500
 - 69s - loss: 0.0043 - f_mera: 0.7086 - val_loss: 0.0048 - val_f_mera: 0.6918
Epoch 362/500
 - 68s - loss: 0.0043 - f_mera: 0.7084 - val_loss: 0.0047 - val_f_mera: 0.6905
Epoch 363/500
 - 68s - loss: 0.0043 - f_mera: 0.7072 - val_loss: 0.0048 - val_f_mera: 0.6889
Epoch 364/500
 - 68s - loss: 0.0043 - f_mera: 0.7087 - val_loss: 0.0048 - val_f_mera: 0.6892
Epoch 365/500
 - 68s - loss: 0.0043 - f_mera: 0.7090 - val_loss: 0.0048 - val_f_mera: 0.6876
Epoch 366/500
 - 68s - loss: 0.0043 - f_mera: 0.7097 - val_loss: 0.0048 - val_f_mera: 0.6924
Epoch 367/500
 - 68s - loss: 0.0043 - f_mera: 0.7092 - val_loss: 0.0048 - val_f_mera: 0.6890
Epoch 368/500
 - 68s - loss: 0.0043 - f_mera: 0.7099 - val_loss: 0.0048 - val_f_mera: 0.6926
Epoch 369/500
 - 68s - loss: 0.0043 - f_mera: 0.7099 - val_loss: 0.0048 - val_f_mera: 0.6923
Epoch 370/500
 - 68s - loss: 0.0043 - f_mera: 0.7100 - val_loss: 0.0047 - val_f_mera: 0.6911
Epoch 371/500
 - 68s - loss: 0.0043 - f_mera: 0.7089 - val_loss: 0.0048 - val_f_mera: 0.6904
Epoch 372/500
 - 68s - loss: 0.0043 - f_mera: 0.7096 - val_loss: 0.0048 - val_f_mera: 0.6920
Epoch 373/500
 - 68s - loss: 0.0043 - f_mera: 0.7089 - val_loss: 0.0048 - val_f_mera: 0.6897
Epoch 374/500
 - 68s - loss: 0.0043 - f_mera: 0.7108 - val_loss: 0.0048 - val_f_mera: 0.6910
Epoch 375/500
 - 68s - loss: 0.0043 - f_mera: 0.7105 - val_loss: 0.0048 - val_f_mera: 0.6923
Epoch 376/500
 - 68s - loss: 0.0043 - f_mera: 0.7099 - val_loss: 0.0047 - val_f_mera: 0.6895
Epoch 377/500
 - 68s - loss: 0.0043 - f_mera: 0.7092 - val_loss: 0.0048 - val_f_mera: 0.6942
Epoch 378/500
 - 68s - loss: 0.0043 - f_mera: 0.7099 - val_loss: 0.0047 - val_f_mera: 0.6918
Epoch 379/500
 - 68s - loss: 0.0042 - f_mera: 0.7105 - val_loss: 0.0048 - val_f_mera: 0.6903
Epoch 380/500
 - 68s - loss: 0.0043 - f_mera: 0.7103 - val_loss: 0.0050 - val_f_mera: 0.6924
Epoch 381/500
 - 68s - loss: 0.0043 - f_mera: 0.7076 - val_loss: 0.0047 - val_f_mera: 0.6913
Epoch 382/500
 - 68s - loss: 0.0043 - f_mera: 0.7105 - val_loss: 0.0048 - val_f_mera: 0.6862
Epoch 383/500
 - 68s - loss: 0.0043 - f_mera: 0.7100 - val_loss: 0.0048 - val_f_mera: 0.6812
Epoch 384/500
 - 68s - loss: 0.0042 - f_mera: 0.7100 - val_loss: 0.0048 - val_f_mera: 0.6878
Epoch 385/500
 - 69s - loss: 0.0043 - f_mera: 0.7089 - val_loss: 0.0048 - val_f_mera: 0.6909
Epoch 386/500
 - 68s - loss: 0.0043 - f_mera: 0.7088 - val_loss: 0.0048 - val_f_mera: 0.6905
Epoch 387/500
 - 68s - loss: 0.0042 - f_mera: 0.7095 - val_loss: 0.0048 - val_f_mera: 0.6881
Epoch 388/500
 - 68s - loss: 0.0042 - f_mera: 0.7100 - val_loss: 0.0047 - val_f_mera: 0.6909
Epoch 389/500
 - 68s - loss: 0.0042 - f_mera: 0.7103 - val_loss: 0.0048 - val_f_mera: 0.6942
Epoch 390/500
 - 68s - loss: 0.0042 - f_mera: 0.7110 - val_loss: 0.0048 - val_f_mera: 0.6903
Epoch 391/500
 - 68s - loss: 0.0042 - f_mera: 0.7105 - val_loss: 0.0048 - val_f_mera: 0.6928
Epoch 392/500
 - 68s - loss: 0.0042 - f_mera: 0.7101 - val_loss: 0.0049 - val_f_mera: 0.6896
Epoch 393/500
 - 68s - loss: 0.0042 - f_mera: 0.7090 - val_loss: 0.0047 - val_f_mera: 0.6903
Epoch 394/500
 - 68s - loss: 0.0042 - f_mera: 0.7113 - val_loss: 0.0048 - val_f_mera: 0.6911
Epoch 395/500
 - 68s - loss: 0.0042 - f_mera: 0.7102 - val_loss: 0.0048 - val_f_mera: 0.6938
Epoch 396/500
 - 69s - loss: 0.0042 - f_mera: 0.7106 - val_loss: 0.0047 - val_f_mera: 0.6873
Epoch 397/500
 - 68s - loss: 0.0043 - f_mera: 0.7096 - val_loss: 0.0048 - val_f_mera: 0.6929
Epoch 398/500
 - 69s - loss: 0.0043 - f_mera: 0.7083 - val_loss: 0.0048 - val_f_mera: 0.6928
Epoch 399/500
 - 68s - loss: 0.0043 - f_mera: 0.7078 - val_loss: 0.0048 - val_f_mera: 0.6900
Epoch 400/500
 - 68s - loss: 0.0042 - f_mera: 0.7107 - val_loss: 0.0049 - val_f_mera: 0.6928
Epoch 401/500
 - 68s - loss: 0.0042 - f_mera: 0.7114 - val_loss: 0.0048 - val_f_mera: 0.6957
Epoch 402/500
 - 68s - loss: 0.0042 - f_mera: 0.7118 - val_loss: 0.0047 - val_f_mera: 0.6885
Epoch 403/500
 - 68s - loss: 0.0042 - f_mera: 0.7113 - val_loss: 0.0049 - val_f_mera: 0.6882
Epoch 404/500
 - 69s - loss: 0.0042 - f_mera: 0.7104 - val_loss: 0.0048 - val_f_mera: 0.6876
Epoch 405/500
 - 69s - loss: 0.0043 - f_mera: 0.7086 - val_loss: 0.0047 - val_f_mera: 0.6898
Epoch 406/500
 - 68s - loss: 0.0042 - f_mera: 0.7109 - val_loss: 0.0048 - val_f_mera: 0.6926
Epoch 407/500
 - 68s - loss: 0.0042 - f_mera: 0.7109 - val_loss: 0.0048 - val_f_mera: 0.6879
Epoch 408/500
 - 68s - loss: 0.0042 - f_mera: 0.7098 - val_loss: 0.0047 - val_f_mera: 0.6915
Epoch 409/500
 - 68s - loss: 0.0042 - f_mera: 0.7129 - val_loss: 0.0047 - val_f_mera: 0.6906
Epoch 410/500
 - 68s - loss: 0.0042 - f_mera: 0.7106 - val_loss: 0.0047 - val_f_mera: 0.6829
Epoch 411/500
 - 68s - loss: 0.0042 - f_mera: 0.7113 - val_loss: 0.0048 - val_f_mera: 0.6866
Epoch 412/500
 - 68s - loss: 0.0042 - f_mera: 0.7097 - val_loss: 0.0048 - val_f_mera: 0.6886
Epoch 413/500
 - 68s - loss: 0.0042 - f_mera: 0.7097 - val_loss: 0.0048 - val_f_mera: 0.6863
Epoch 414/500
 - 69s - loss: 0.0042 - f_mera: 0.7101 - val_loss: 0.0047 - val_f_mera: 0.6927
Epoch 415/500
 - 68s - loss: 0.0042 - f_mera: 0.7120 - val_loss: 0.0048 - val_f_mera: 0.6933
Epoch 416/500
 - 68s - loss: 0.0042 - f_mera: 0.7112 - val_loss: 0.0048 - val_f_mera: 0.6923
Epoch 417/500
 - 69s - loss: 0.0042 - f_mera: 0.7104 - val_loss: 0.0048 - val_f_mera: 0.6924
Epoch 418/500
 - 68s - loss: 0.0043 - f_mera: 0.7074 - val_loss: 0.0048 - val_f_mera: 0.6850
Epoch 419/500
 - 68s - loss: 0.0042 - f_mera: 0.7087 - val_loss: 0.0048 - val_f_mera: 0.6892
Epoch 420/500
 - 68s - loss: 0.0042 - f_mera: 0.7103 - val_loss: 0.0048 - val_f_mera: 0.6907
Epoch 421/500
 - 68s - loss: 0.0042 - f_mera: 0.7110 - val_loss: 0.0048 - val_f_mera: 0.6960
Epoch 422/500
 - 68s - loss: 0.0042 - f_mera: 0.7117 - val_loss: 0.0048 - val_f_mera: 0.6912
Epoch 423/500
 - 68s - loss: 0.0042 - f_mera: 0.7108 - val_loss: 0.0047 - val_f_mera: 0.6923
Epoch 424/500
 - 69s - loss: 0.0043 - f_mera: 0.7036 - val_loss: 0.0048 - val_f_mera: 0.6873
Epoch 425/500
 - 68s - loss: 0.0042 - f_mera: 0.7099 - val_loss: 0.0048 - val_f_mera: 0.6927
Epoch 426/500
 - 68s - loss: 0.0042 - f_mera: 0.7093 - val_loss: 0.0048 - val_f_mera: 0.6914
Epoch 427/500
 - 68s - loss: 0.0042 - f_mera: 0.7094 - val_loss: 0.0048 - val_f_mera: 0.6831
Epoch 428/500
 - 68s - loss: 0.0042 - f_mera: 0.7093 - val_loss: 0.0048 - val_f_mera: 0.6896
Epoch 429/500
 - 68s - loss: 0.0042 - f_mera: 0.7120 - val_loss: 0.0048 - val_f_mera: 0.6915
Epoch 430/500
 - 68s - loss: 0.0042 - f_mera: 0.7098 - val_loss: 0.0047 - val_f_mera: 0.6843
Epoch 431/500
 - 68s - loss: 0.0042 - f_mera: 0.7110 - val_loss: 0.0047 - val_f_mera: 0.6897
Epoch 432/500
 - 68s - loss: 0.0042 - f_mera: 0.7122 - val_loss: 0.0047 - val_f_mera: 0.6921
Epoch 433/500
 - 68s - loss: 0.0042 - f_mera: 0.7114 - val_loss: 0.0047 - val_f_mera: 0.6895
Epoch 434/500
 - 68s - loss: 0.0042 - f_mera: 0.7096 - val_loss: 0.0048 - val_f_mera: 0.6918
Epoch 435/500
 - 68s - loss: 0.0042 - f_mera: 0.7126 - val_loss: 0.0048 - val_f_mera: 0.6934
Epoch 436/500
 - 68s - loss: 0.0042 - f_mera: 0.7137 - val_loss: 0.0047 - val_f_mera: 0.6941
Epoch 437/500
 - 69s - loss: 0.0042 - f_mera: 0.7110 - val_loss: 0.0047 - val_f_mera: 0.6911
Epoch 438/500
 - 68s - loss: 0.0042 - f_mera: 0.7118 - val_loss: 0.0048 - val_f_mera: 0.6935
Epoch 439/500
 - 68s - loss: 0.0042 - f_mera: 0.7115 - val_loss: 0.0047 - val_f_mera: 0.6907
Epoch 440/500
 - 68s - loss: 0.0042 - f_mera: 0.7131 - val_loss: 0.0047 - val_f_mera: 0.6899
Epoch 441/500
 - 68s - loss: 0.0042 - f_mera: 0.7139 - val_loss: 0.0047 - val_f_mera: 0.6954
Epoch 442/500
 - 68s - loss: 0.0042 - f_mera: 0.7120 - val_loss: 0.0047 - val_f_mera: 0.6916
Epoch 443/500
 - 68s - loss: 0.0042 - f_mera: 0.7118 - val_loss: 0.0048 - val_f_mera: 0.6958
Epoch 444/500
 - 68s - loss: 0.0042 - f_mera: 0.7127 - val_loss: 0.0047 - val_f_mera: 0.6916
Epoch 445/500
 - 68s - loss: 0.0042 - f_mera: 0.7136 - val_loss: 0.0047 - val_f_mera: 0.6969
Epoch 446/500
 - 68s - loss: 0.0042 - f_mera: 0.7128 - val_loss: 0.0047 - val_f_mera: 0.6852
Epoch 447/500
 - 69s - loss: 0.0042 - f_mera: 0.7119 - val_loss: 0.0048 - val_f_mera: 0.6939
Epoch 448/500
 - 68s - loss: 0.0042 - f_mera: 0.7110 - val_loss: 0.0047 - val_f_mera: 0.6951
Epoch 449/500
 - 68s - loss: 0.0042 - f_mera: 0.7143 - val_loss: 0.0048 - val_f_mera: 0.6963
Epoch 450/500
 - 69s - loss: 0.0042 - f_mera: 0.7124 - val_loss: 0.0047 - val_f_mera: 0.6933
Epoch 451/500
 - 68s - loss: 0.0042 - f_mera: 0.7127 - val_loss: 0.0047 - val_f_mera: 0.6862
Epoch 452/500
 - 68s - loss: 0.0042 - f_mera: 0.7133 - val_loss: 0.0047 - val_f_mera: 0.6913
Epoch 453/500
 - 68s - loss: 0.0042 - f_mera: 0.7123 - val_loss: 0.0047 - val_f_mera: 0.6914
Epoch 454/500
 - 68s - loss: 0.0042 - f_mera: 0.7133 - val_loss: 0.0047 - val_f_mera: 0.6944
Epoch 455/500
 - 69s - loss: 0.0042 - f_mera: 0.7138 - val_loss: 0.0047 - val_f_mera: 0.6935
Epoch 456/500
 - 68s - loss: 0.0042 - f_mera: 0.7131 - val_loss: 0.0047 - val_f_mera: 0.6889
Epoch 457/500
 - 68s - loss: 0.0042 - f_mera: 0.7118 - val_loss: 0.0048 - val_f_mera: 0.6875
Epoch 458/500
 - 68s - loss: 0.0042 - f_mera: 0.7129 - val_loss: 0.0047 - val_f_mera: 0.6907
Epoch 459/500
 - 68s - loss: 0.0042 - f_mera: 0.7136 - val_loss: 0.0047 - val_f_mera: 0.6929
Epoch 460/500
 - 68s - loss: 0.0042 - f_mera: 0.7139 - val_loss: 0.0047 - val_f_mera: 0.6942
Epoch 461/500
 - 69s - loss: 0.0042 - f_mera: 0.7140 - val_loss: 0.0047 - val_f_mera: 0.6967
Epoch 462/500
 - 68s - loss: 0.0042 - f_mera: 0.7096 - val_loss: 0.0047 - val_f_mera: 0.6826
Epoch 463/500
 - 69s - loss: 0.0042 - f_mera: 0.7110 - val_loss: 0.0047 - val_f_mera: 0.6908
Epoch 464/500
 - 69s - loss: 0.0042 - f_mera: 0.7128 - val_loss: 0.0047 - val_f_mera: 0.6944
Epoch 465/500
 - 68s - loss: 0.0042 - f_mera: 0.7139 - val_loss: 0.0048 - val_f_mera: 0.6873
Epoch 466/500
 - 68s - loss: 0.0042 - f_mera: 0.7141 - val_loss: 0.0048 - val_f_mera: 0.6926
Epoch 467/500
 - 69s - loss: 0.0042 - f_mera: 0.7152 - val_loss: 0.0047 - val_f_mera: 0.6915
Epoch 468/500
 - 68s - loss: 0.0042 - f_mera: 0.7140 - val_loss: 0.0047 - val_f_mera: 0.6939
Epoch 469/500
 - 68s - loss: 0.0042 - f_mera: 0.7128 - val_loss: 0.0047 - val_f_mera: 0.6912
Epoch 470/500
 - 69s - loss: 0.0042 - f_mera: 0.7123 - val_loss: 0.0047 - val_f_mera: 0.6904
Epoch 471/500
 - 69s - loss: 0.0042 - f_mera: 0.7121 - val_loss: 0.0047 - val_f_mera: 0.6895
Epoch 472/500
 - 69s - loss: 0.0042 - f_mera: 0.7118 - val_loss: 0.0047 - val_f_mera: 0.6896
Epoch 473/500
 - 68s - loss: 0.0042 - f_mera: 0.7114 - val_loss: 0.0047 - val_f_mera: 0.6917
Epoch 474/500
 - 68s - loss: 0.0042 - f_mera: 0.7136 - val_loss: 0.0047 - val_f_mera: 0.6925
Epoch 475/500
 - 68s - loss: 0.0042 - f_mera: 0.7133 - val_loss: 0.0047 - val_f_mera: 0.6954
Epoch 476/500
 - 68s - loss: 0.0042 - f_mera: 0.7151 - val_loss: 0.0047 - val_f_mera: 0.6855
Epoch 477/500
 - 68s - loss: 0.0042 - f_mera: 0.7128 - val_loss: 0.0047 - val_f_mera: 0.6882
Epoch 478/500
 - 68s - loss: 0.0042 - f_mera: 0.7142 - val_loss: 0.0047 - val_f_mera: 0.6907
Epoch 479/500
 - 69s - loss: 0.0042 - f_mera: 0.7147 - val_loss: 0.0048 - val_f_mera: 0.6925
Epoch 480/500
 - 68s - loss: 0.0042 - f_mera: 0.7151 - val_loss: 0.0047 - val_f_mera: 0.6886
Epoch 481/500
 - 68s - loss: 0.0042 - f_mera: 0.7151 - val_loss: 0.0047 - val_f_mera: 0.6968
Epoch 482/500
 - 68s - loss: 0.0042 - f_mera: 0.7145 - val_loss: 0.0048 - val_f_mera: 0.6922
Epoch 483/500
 - 69s - loss: 0.0042 - f_mera: 0.7148 - val_loss: 0.0047 - val_f_mera: 0.6963
Epoch 484/500
 - 68s - loss: 0.0042 - f_mera: 0.7154 - val_loss: 0.0048 - val_f_mera: 0.6956
Epoch 485/500
 - 68s - loss: 0.0042 - f_mera: 0.7130 - val_loss: 0.0047 - val_f_mera: 0.6930
Epoch 486/500
 - 69s - loss: 0.0042 - f_mera: 0.7152 - val_loss: 0.0047 - val_f_mera: 0.6908
Epoch 487/500
 - 69s - loss: 0.0042 - f_mera: 0.7151 - val_loss: 0.0047 - val_f_mera: 0.6923
Epoch 488/500
 - 68s - loss: 0.0042 - f_mera: 0.7122 - val_loss: 0.0047 - val_f_mera: 0.6921
Epoch 489/500
 - 68s - loss: 0.0042 - f_mera: 0.7147 - val_loss: 0.0047 - val_f_mera: 0.6941
Epoch 490/500
 - 69s - loss: 0.0042 - f_mera: 0.7159 - val_loss: 0.0047 - val_f_mera: 0.6929
Epoch 491/500
 - 69s - loss: 0.0042 - f_mera: 0.7128 - val_loss: 0.0048 - val_f_mera: 0.6972
Epoch 492/500
 - 68s - loss: 0.0042 - f_mera: 0.7144 - val_loss: 0.0048 - val_f_mera: 0.6971
Epoch 493/500
 - 68s - loss: 0.0042 - f_mera: 0.7154 - val_loss: 0.0048 - val_f_mera: 0.6942
Epoch 494/500
 - 68s - loss: 0.0042 - f_mera: 0.7154 - val_loss: 0.0047 - val_f_mera: 0.6980
Epoch 495/500
 - 68s - loss: 0.0042 - f_mera: 0.7147 - val_loss: 0.0047 - val_f_mera: 0.6912
Epoch 496/500
 - 68s - loss: 0.0042 - f_mera: 0.7105 - val_loss: 0.0047 - val_f_mera: 0.6893
Epoch 497/500
 - 69s - loss: 0.0042 - f_mera: 0.7142 - val_loss: 0.0048 - val_f_mera: 0.6937
Epoch 498/500
 - 68s - loss: 0.0042 - f_mera: 0.7135 - val_loss: 0.0047 - val_f_mera: 0.6860
Epoch 499/500
 - 68s - loss: 0.0042 - f_mera: 0.7127 - val_loss: 0.0047 - val_f_mera: 0.6939
Epoch 500/500
 - 68s - loss: 0.0042 - f_mera: 0.7133 - val_loss: 0.0048 - val_f_mera: 0.6878
